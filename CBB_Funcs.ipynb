{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "def running_means(scores, opp_scores, mean_scores, threes, opp_threes, fg_pct, opp_fg_pct):\n",
    "    \"\"\"\n",
    "        Function takes in (scores, opp_scores) which are lists of a team's scores\n",
    "        and the scores of its opponents. The function returns two lists which \n",
    "        are the running means of the team and the team's previous opponents.\n",
    "    \"\"\"\n",
    "    \n",
    "    # 'means' and opp_means are initialized with a NaN value because there is no\n",
    "    # previous data to grab before the first game\n",
    "    means = [np.nan]\n",
    "    opp_means = [np.nan]\n",
    "    avg_mean_scores = [np.nan]\n",
    "    avg_threes = [np.nan]\n",
    "    avg_opp_threes = [np.nan]\n",
    "    avg_fg_pct = [np.nan]\n",
    "    avg_opp_fg_pct = [np.nan]\n",
    "    \n",
    "    # loops through each score and opponent score beginning with game 2\n",
    "    for idx, (score, opp_score)  in enumerate(zip(scores[1:], opp_scores[1:])):\n",
    "        \n",
    "        # appends the running means\n",
    "        means.append(scores[:idx+1].mean())\n",
    "        opp_means.append(opp_scores[:idx+1].mean())\n",
    "        avg_mean_scores.append(mean_scores[:idx+1].mean())\n",
    "        avg_fg_pct.append(fg_pct[:idx+1].mean())\n",
    "        avg_opp_fg_pct.append(opp_fg_pct[:idx+1].mean())\n",
    "        \n",
    "        # calculates percentage of points scored and given up by threes and then substracts the pre-calculated league average\n",
    "        avg_threes.append(((threes[:idx+1]*3).mean() / means[idx+1]) - threes_pct)\n",
    "        avg_opp_threes.append(((opp_threes[:idx+1]*3).mean() / opp_means[idx+1]) - threes_pct) \n",
    "\n",
    "    return means, opp_means, avg_mean_scores, avg_threes, avg_opp_threes, avg_fg_pct, avg_opp_fg_pct\n",
    "\n",
    "def get_logistics(year):\n",
    "    # Grabs logistical data about the college basketball teams\n",
    "    sources = teams_source[year].dropna()                  # website sources for each team\n",
    "    teams = teams_source[year + '_Teams'].dropna()         # names of teams \n",
    "    team_nums = list(range(len(teams))) # idx numbers for each team\n",
    "    team_dict = {teams[num]: num for num in team_nums}\n",
    "    \n",
    "    return year, sources, teams, team_dict\n",
    "\n",
    "def get_linear_stats(X, y, n_runs=10, n_folds=10):\n",
    "    \"\"\"\n",
    "        Takes in X and y data and returns Linear Model statistics.\n",
    "        Returns Standard Error, Standard Deviation, Mean Squared Error,\n",
    "        Cross-Validation Score, and statsmodels OLS results.\n",
    "        \n",
    "        n_runs is the number of training runs to perform. An increase in n_runs\n",
    "        provides more stable results.\n",
    "        \n",
    "        n_folds is the number of folds to create in the cross-validation test\n",
    "    \"\"\"\n",
    "    \n",
    "    # Initialized Linear Regression model\n",
    "    lr = LinearRegression()\n",
    "    \n",
    "    # drops null values from data input\n",
    "    X = X.dropna()\n",
    "    y = y.dropna()\n",
    "    \n",
    "    # number for features in model\n",
    "    num_features = X.shape[1]\n",
    "    \n",
    "    # initializes statistics that will be averaged\n",
    "    MSEs = []\n",
    "    SE = []\n",
    "    stds = []\n",
    "    scores = []\n",
    "    pct_acc = []\n",
    "    cv = []\n",
    "    coefs = []\n",
    "    \n",
    "    # Number of training runs\n",
    "    # Increase in runs stabilizes results\n",
    "    for ii in range(n_runs):\n",
    "        \n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "\n",
    "        lr.fit_intercept = False\n",
    "        lr.fit(X_train, y_train)\n",
    "\n",
    "        y_pred = lr.predict(X_test)\n",
    "        \n",
    "        # Difference between predicted results and test data\n",
    "        resid = y_pred - y_test\n",
    "        \n",
    "        # Append statistics\n",
    "        SE.append(np.std(resid, ddof=num_features) / np.sqrt(np.size(resid)))\n",
    "        stds.append(np.std(resid, ddof=num_features))\n",
    "        MSEs.append(mean_squared_error(y_test, y_pred))\n",
    "        scores.append(lr.score(X_test, y_test))\n",
    "        \n",
    "         # Show percent accuracy of predicting win/loss\n",
    "        num_correct = 0\n",
    "        for pred, act in zip(y_pred, y_test):\n",
    "            if pred*act > 0:\n",
    "                num_correct += 1\n",
    "        pct_acc.append(num_correct/len(y_test))\n",
    "        \n",
    "        coefs.append(lr.coef_)\n",
    "        \n",
    "        cv.append(cross_val_score(LinearRegression(), X, y, cv=KFold(n_folds, shuffle=True)).mean())\n",
    "   \n",
    "    \n",
    "    # Develop OLS model\n",
    "    model = sm.OLS(y_train, X_train, missing = 'drop') # sm.add_constant(X)\n",
    "    results = model.fit()\n",
    "    \n",
    "    return np.mean(SE), np.mean(stds), np.mean(MSEs), np.mean(cv), results, np.mean(pct_acc)*100, np.mean(coefs, axis=0)\n",
    "\n",
    "def get_logistic_stats(X, y, n_runs=10, n_folds=10):\n",
    "    \"\"\"\n",
    "        Takes in X and y data and returns Logistic Model statistics.\n",
    "        Returns Percent Accuracy.\n",
    "        \n",
    "        n_runs is the number of training runs to perform. An increase in n_runs\n",
    "        provides more stable results.\n",
    "        \n",
    "        n_folds is the number of folds to create in the cross-validation test\n",
    "    \"\"\"\n",
    "\n",
    "    # drops null values from data input\n",
    "    X = X.dropna()\n",
    "    y = y.dropna()\n",
    "    \n",
    "    sc = StandardScaler()\n",
    "    X = sc.fit_transform(X)\n",
    "\n",
    "    # Initialized Logistic Regression model\n",
    "    lr = LogisticRegression(max_iter=1000)\n",
    "    \n",
    "    # initializes statistics that will be averaged\n",
    "    cv = []\n",
    "    coefs = []\n",
    "    \n",
    "    # Number of training runs\n",
    "    # Increase in runs stabilizes results\n",
    "    for ii in range(n_runs):\n",
    "        \n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "\n",
    "        lr.fit(X_train, y_train)\n",
    "\n",
    "        coefs.append(lr.coef_)\n",
    "        \n",
    "        cv.append(cross_val_score(LogisticRegression(max_iter=1000), X, y, cv=KFold(n_folds, shuffle=True)).mean())\n",
    "    \n",
    "    return np.mean(cv)*100, np.mean(coefs, axis=0)\n",
    "\n",
    "def webscrape_data(year, sources, teams):\n",
    "    dataframes = [] # list of dataframes\n",
    "\n",
    "    # Loops through each team listed in the sources list of urls\n",
    "    for ii, src in enumerate(sources):\n",
    "        content = urllib.request.urlopen(src) # opens content of url\n",
    "        read_content = content.read()   # reads content\n",
    "\n",
    "        soup = BeautifulSoup(read_content,'html.parser')  # pass the content to BeautifulSoup to parse\n",
    "        tags = soup.find_all('td') # grab only tags with 'td' which grabs the data table from the website\n",
    "\n",
    "        data = []\n",
    "        row = []\n",
    "        # loops through extracted tag\n",
    "        for idx, tr in enumerate(tags):\n",
    "            row.append(tr.text) # appends text of the tag\n",
    "\n",
    "            # Given that there are 39 columns of data in the table,\n",
    "            # a check is perfromed on if the tag is the last tag\n",
    "            # in the row\n",
    "            if (idx + 1)%39 == 0: \n",
    "\n",
    "                # if the opponent team name ('idx 3'), does not an 'a' href,\n",
    "                # then that team is not a Division 1 school and will not have \n",
    "                # data of its own in the dataframe. Because the program will use\n",
    "                # data from the opponent, all data from non-Division 1 schools\n",
    "                # is removed.\n",
    "                if tags[idx - 36].find('a'):\n",
    "                    data.append(row) # row of data is appended to data list if opponent is Division 1\n",
    "                row = []\n",
    "\n",
    "        # Removes cancelled game between Hampton and Morgan State\n",
    "        # Score was 2-0 at the time of cancellation\n",
    "        if (year == '2018') and ((ii == 112) or (ii == 191)):\n",
    "            if ii == 112:\n",
    "                data = data[:26] + data[27:]\n",
    "            else:\n",
    "                data = data[:24] + data[25:]\n",
    "\n",
    "        # dataframe is created and key columns are renamed to better represent the data\n",
    "        df = pd.DataFrame(data).rename(columns = {0: 'Date', 1: 'Loc', 2: 'Opp_name', 3: 'Win', 4: 'Score', 5: 'Opp_score', 8: 'FG_Pct', 9:'Threes', 25: 'Opp_FG_Pct', 9:'Threes', 26: 'Opp_Threes'})\n",
    "\n",
    "        # datatypes of numerical columns are changed to floats \n",
    "        try:\n",
    "            df = df.astype({key: float for key in df.keys() if key not in ['Date', 'Loc', 'Opp_name', 'Win', 22]})\n",
    "        except ValueError: # handles value errors (by looking through the data it was determined there are a few instances where a cell was left blank)\n",
    "            for col in df: # iterates through each column in dataframe\n",
    "                float_vals = []\n",
    "                for val in df[col]: # iterates through each value in column\n",
    "                    try:\n",
    "                        float_vals.append(float(val)) # converts to float if possible\n",
    "                    except ValueError:   # used for values that cannot be converted to float\n",
    "                        if col not in ['Date', 'Loc', 'Opp_name', 'Win', 22]:  # checks to make sure it wasn't supposed to be a String\n",
    "                            float_vals.append(np.nan) # replace blank space with NaN\n",
    "                        else:\n",
    "                            float_vals.append(val) # leaves value as is\n",
    "\n",
    "                df[col] = pd.Series(float_vals) # replaces column with new \"float_values\"\n",
    "\n",
    "        # Convert 'Date' to datetime for evaluation later in runtime\n",
    "        df['Date'] = pd.to_datetime(df['Date'])\n",
    "\n",
    "        # The result column is added which represents how much the team lost or won by in that game\n",
    "        # This will be the y-vector that the prediction model uses.\n",
    "        df['result'] = df['Score'] - df['Opp_score']\n",
    "        \n",
    "        # The 'Win' column is 1 if the team won the game and 0 otherwise.\n",
    "        # This will be another y-vector that the model predicts\n",
    "        df['Win'] = np.where(df['result'] > 0, 1, 0)\n",
    "\n",
    "        # Keep track of the Game Number\n",
    "        df['Game_Number'] = list(range(1, len(df) + 1))\n",
    "\n",
    "        # Calcultes the mean score of each game ( (team_score + opp_score) / 2 )\n",
    "        df['Mean_Score'] = df[['Score', 'Opp_score']].mean(axis = 1)\n",
    "\n",
    "        # Columns that represent the average scores of both the team and team's previous opponents\n",
    "        # are added to the dataframe. This is done by calling the \"running_means\" function.\n",
    "        # The data represents the averages going into the game\n",
    "        df['Avg_Score'], df['Opp_Avg_Score'], df['Avg_Mean_Score'], df['Avg_Threes'], df['Opp_Avg_Threes'], df['Avg_FG_Pct'], df['Opp_Avg_FG_Pct'] = \\\n",
    "        running_means(df['Score'], df['Opp_score'], df['Mean_Score'], df['Threes'], df['Opp_Threes'], df['FG_Pct'], df['Opp_FG_Pct'])\n",
    "\n",
    "        # Calculates the average value of vicotry/loss\n",
    "        df['Avg_Result'] = df['Avg_Score'] - df['Opp_Avg_Score']\n",
    "\n",
    "        # Calculates the percent margin of victory/loss as percentage of mean scores\n",
    "        df['Pct_Margin'] = df['Avg_Result'] / df['Avg_Mean_Score']\n",
    "\n",
    "        # Create Dummy Variables for Home and Away\n",
    "        location = pd.get_dummies(df['Loc'])\n",
    "        if location.shape[1] == 3:\n",
    "            location.columns = ['Home', 'Away', 'Neutral']\n",
    "        else: # needed for teams that don't have any neutral-site games\n",
    "            location.columns = ['Home', 'Away']   \n",
    "\n",
    "        # concatenate original dataframe to new location dummy dataframe\n",
    "        df = pd.concat((df, location), axis = 1)\n",
    "\n",
    "        # create a column that contains the average season result in every row\n",
    "        df['Avg_Result_Fin'] = [df['Score'].mean() - df['Opp_score'].mean()] * len(df)\n",
    "\n",
    "        # Create a column that contains just the average result from non-conference games (first 10 games)\n",
    "        df['Avg_Result_NC'] = list(df['Avg_Result'][:10]) + [df['Avg_Result'][9]] * (len(df) - 10)\n",
    "\n",
    "        # saves dataframe\n",
    "        df.to_csv('./Team_Dataframes/' + year + '/Team_Only/' + teams[ii] + '.csv', index = False)\n",
    "\n",
    "        # add dataframe to list of dataframes\n",
    "        dataframes.append(df)\n",
    "    \n",
    "    print('DONE WITH DATA INTAKE', year)\n",
    "    return dataframes\n",
    "\n",
    "def load_frames(teams=[], year='2016', multiple=False):\n",
    "    \n",
    "    if multiple:\n",
    "        \n",
    "        dataframes = pd.read_csv('./Final_Dataframes/Teams_Only.csv')\n",
    "        \n",
    "        dataframes['Date'] = pd.to_datetime(dataframes['Date'])\n",
    "    \n",
    "    else:\n",
    "        \n",
    "        dataframes = [pd.read_csv('./Team_Dataframes/' + year + '/Team_Only/' + teams[ii] + '.csv') for ii in range(len(teams))]\n",
    "\n",
    "        for df in dataframes:\n",
    "\n",
    "            # Convert 'Date' to datetime for evaluation later in runtime\n",
    "            df['Date'] = pd.to_datetime(df['Date'])\n",
    "    \n",
    "    print('DONE LOADING FRAMES')\n",
    "    \n",
    "    return dataframes\n",
    "\n",
    "# Grabs logistical data about the college basketball teams\n",
    "def get_team_data(year='2016', multiple=False, scrape_data=False):\n",
    "    \"\"\"\n",
    "       Returns team-specific data. Default arguments (year='2016', multiple=False, scrape_data=False).\n",
    "       'year' specificies which year of data to collect.\n",
    "       'multiple' will return only the 'year' of data when set to False, but will return all years when set to True\n",
    "       'scrape_data' will load existing data if set to False, but will scrape data from the web if set to True\n",
    "    \"\"\"\n",
    "\n",
    "    if multiple:\n",
    "\n",
    "        years = ['2016', '2017', '2018', '2019']\n",
    "\n",
    "        ## run if scraping new data\n",
    "        if scrape_data:\n",
    "\n",
    "            tot_frame = []\n",
    "\n",
    "            for year in years:\n",
    "\n",
    "                # grab logistical data such as web sources and team names\n",
    "                year, sources, teams, team_dict = get_logistics(year)\n",
    "                dataframes = webscrape_data(year, sources, teams)\n",
    "                tot_frame.append(pd.concat((dataframes)))\n",
    "\n",
    "            tot_frame = pd.concat((tot_frame))\n",
    "            tot_frame.to_csv('./Final_Dataframes/Teams_Only.csv', index=False)\n",
    "\n",
    "        ## run if loading existing \n",
    "        else:\n",
    "\n",
    "            tot_frame = load_frames(multiple=True)\n",
    "            \n",
    "        return tot_frame, '', ''\n",
    "\n",
    "    else:\n",
    "\n",
    "        year, sources, teams, team_dict = get_logistics(year)\n",
    "\n",
    "        ## run if scraping new data\n",
    "        if scrape_data:\n",
    "\n",
    "            dataframes = webscrape_data(year, sources, teams)\n",
    "\n",
    "        ## run if loading existing \n",
    "        else:\n",
    "\n",
    "            dataframes = load_frames(teams=teams, year=year)\n",
    "\n",
    "        return dataframes, teams, team_dict\n",
    "    \n",
    "def combine_data(dataframes, team_dict, teams, year='2016'):\n",
    "    \"\"\"\n",
    "    Takes in a list of dataframes\n",
    "    Function looks at team's opponents' dataframes and concatenates the team's dataframe\n",
    "    with data from the opponents.\n",
    "    Returns a list of concatenated dataframes for each team\n",
    "    \"\"\"\n",
    "    \n",
    "    # Initialize a list of dataframes that will combine a team's dataframe with data from its opponents\n",
    "    combined_df = []\n",
    "\n",
    "    # loop through each dataframe (team)\n",
    "    for ii, df in enumerate(dataframes):\n",
    "\n",
    "        # initialize a list that will represent the strength of schedule of the team entering the game\n",
    "        # initialized with NaN because there would be no previous opponents entering the first game\n",
    "        sos = [np.nan]\n",
    "        sos_all = [np.nan] # uses final average result from each previous opponent\n",
    "        sos_nc = [np.nan] # team's non-conference SOS\n",
    "\n",
    "        # initialize a list that will represent the strength of schedule of the team's previous opponents\n",
    "        # entering the game\n",
    "        # initialized with NaN because there would be no previous opponents entering the first game\n",
    "        prev_sos = [np.nan]\n",
    "        prev_sos_all = [np.nan] # uses final average result from each previous opponent\n",
    "        prev_sos_nc = [np.nan] # team's non-conference SOS\n",
    "\n",
    "        # Initializes a list that will represent the strength of schedule of the opponent entering the game\n",
    "        # This list is not initialized with NaN because the opponent may have already played a game before\n",
    "        # the team's first game\n",
    "        opp_sos =[]\n",
    "        opp_sos_nc = []\n",
    "        opp_prev_opp_sos = []\n",
    "\n",
    "        # list that will contain data of opponent\n",
    "        opp_data = []\n",
    "\n",
    "        # names of all opponents\n",
    "        opp_names = df['Opp_name']\n",
    "        \n",
    "        name_check = teams[ii]\n",
    "\n",
    "        # loops through every game, specifically by enumerating the opponent name column\n",
    "        for idx, name in enumerate(opp_names):\n",
    "            \n",
    "            date_check = df['Date'][idx]\n",
    "            \n",
    "            # will loop through each team's opponent prior to current game\n",
    "            # first checks if idx is greater than 0 because there are no games\n",
    "            # before the first game\n",
    "            if idx > 0:\n",
    "                \n",
    "                # list of all previous opponents\n",
    "                prev_opps = opp_names[:idx]\n",
    "\n",
    "                # list that will store average win/loss results for each previous opponent\n",
    "                avg_results = []\n",
    "                sos_all_results = [] # stores the final average score for each previous opponent\n",
    "                sos_nc_games = []\n",
    "\n",
    "                # lists that will store average win/loss results for each previous opponent's previous opponents\n",
    "                prev_prev_avg_results = []\n",
    "                prev_sos_all_results = []\n",
    "                prev_sos_nc_games = []\n",
    "\n",
    "                # loop through each previous opponent\n",
    "                for jj, prev_name in enumerate(prev_opps):\n",
    "                    # previous opponent dataframe\n",
    "                    prev_df = dataframes[team_dict[prev_name]]\n",
    "                    \n",
    "                    len_prev = len(prev_df)\n",
    "\n",
    "                    # loops through each game for previous opponent\n",
    "                    for idx3, date2 in enumerate(prev_df['Date']):\n",
    "                        if date2 >= date_check:\n",
    "                            prev_avg_result = prev_df['Avg_Result'][idx3]\n",
    "                            prev_opp_prev = prev_df['Opp_name'][:idx3]\n",
    "                            break\n",
    "                        elif idx3 == (len_prev - 1):\n",
    "                            prev_avg_result = prev_df['Avg_Result_Fin'][0]\n",
    "                            prev_opp_prev = prev_df['Opp_name']\n",
    "                            break     \n",
    "\n",
    "                    ## Only grabs index <= 10 as that is about how many pre-conference\n",
    "                    ## games each team plays\n",
    "                    if jj <= 10:\n",
    "                        sos_nc_games.append(prev_avg_result)\n",
    "\n",
    "                    ## append strength of schedule data\n",
    "                    avg_results.append(prev_avg_result)\n",
    "                    sos_all_results.append(prev_df['Avg_Result_Fin'][0])\n",
    "\n",
    "                    # loops through the previous opponents of the previous opponent\n",
    "                    # to find the SOS of previous opponents\n",
    "                    for prev_opp in prev_opp_prev:\n",
    "                        prev2_df = dataframes[team_dict[prev_opp]]\n",
    "                        \n",
    "                        len_prev2 = len(prev2_df)\n",
    "\n",
    "                        for kk, date_kk in enumerate(prev2_df['Date']):\n",
    "                            if date_kk >= date_check:\n",
    "                                #prev_prev_avg_result = prev2_df['result'][:kk].mean()\n",
    "                                prev_prev_avg_result = prev2_df['Avg_Result'][kk]\n",
    "                                break\n",
    "                            elif kk == (len_prev2 - 1):\n",
    "                                #prev_prev_avg_result = prev2_df['result'].mean()\n",
    "                                prev_prev_avg_result = prev2_df['Avg_Result_Fin'][0]\n",
    "                                break   \n",
    "\n",
    "                        ## Only grabs index <= 10 as that is about how many pre-conference\n",
    "                        ## games each team plays\n",
    "                        if kk <= 10:\n",
    "                            prev_sos_nc_games.append(prev_prev_avg_result)\n",
    "\n",
    "                        ## append strength of schedule data\n",
    "                        prev_prev_avg_results.append(prev_prev_avg_result)\n",
    "                        prev_sos_all_results.append(prev2_df['Avg_Result_Fin'][0])\n",
    "\n",
    "                # take means of SOS data to provide singular value for each game\n",
    "                prev_sos.append(np.array(prev_prev_avg_results).mean())\n",
    "                prev_sos_all.append(np.array(prev_sos_all_results).mean())\n",
    "                #prev_sos_nc.append(np.array(prev_sos_nc_games).mean())\n",
    "\n",
    "                # take means of SOS data to provide singular value for each game\n",
    "                sos.append(np.array(avg_results).mean())\n",
    "                sos_all.append(np.array(sos_all_results).mean())\n",
    "                sos_nc.append(np.array(sos_nc_games).mean())\n",
    "\n",
    "            opp_df = dataframes[team_dict[name]] # opponent's dataframe\n",
    "\n",
    "            # loops through each game in opponent's dataframe to find the matching date which\n",
    "            # would represent the same game\n",
    "            for idx2, (date, opp) in enumerate(zip(opp_df['Date'], opp_df['Opp_name'])):    # added the name check to account for few times where teams played twice in a day\n",
    "                if (date == date_check) and (opp == name_check):\n",
    "                    opp_data.append(opp_df.loc[idx2]) # appends data from opponent's game\n",
    "                    break\n",
    "\n",
    "            # will loop through each previous opponent of that game's opponent prior to current game\n",
    "            # first checks if idx2 is greater than 0 because there are no games\n",
    "            # before the first game\n",
    "            if idx2 > 0:\n",
    "\n",
    "                # list of opponent's previous opponents before current game\n",
    "                opp_prev_opps = opp_df['Opp_name'][:idx2]\n",
    "\n",
    "                # list that will store average win/loss results for each opponent of current game's opponent\n",
    "                opp_avg_results = []\n",
    "                opp_sos_nc_games = []\n",
    "                opp_prev_opp_prev_results = []\n",
    "\n",
    "                # loop through each previous opponent of opponent\n",
    "                for kk, opp_prev_name in enumerate(opp_prev_opps):\n",
    "                    \n",
    "                    # previous opponent's opponent dataframe\n",
    "                    opp_prev_df = dataframes[team_dict[opp_prev_name]]\n",
    "                    \n",
    "                    len_opp_prev = len(opp_prev_df)\n",
    "                    \n",
    "                    # checks the dates of games of the opponent's previous opponent \n",
    "                    # will look at games prior to current game date\n",
    "                    for idx4, date3 in enumerate(opp_prev_df['Date']):\n",
    "                        if date3 >= date_check:\n",
    "                            opp_prev_avg_result = opp_prev_df['Avg_Result'][idx4]\n",
    "                            opp_prev_opp_prev = opp_prev_df['Opp_name'][:idx4] # opponent's opponent's previous opponents \n",
    "                            break\n",
    "                        elif idx4 == (len_opp_prev - 1):\n",
    "                            opp_prev_avg_result = opp_prev_df['Avg_Result_Fin'][0]\n",
    "                            opp_prev_opp_prev = opp_prev_df['Opp_name']\n",
    "                            break\n",
    "                    \n",
    "                    opp_prev_opp_prev_result = []\n",
    "                        \n",
    "                    for name2 in opp_prev_opp_prev:\n",
    "\n",
    "                        opp_prev_opp_prev_df = dataframes[team_dict[name2]]\n",
    "                        \n",
    "                        len_opp_prev_opp_prev = len(opp_prev_opp_prev_df)\n",
    "\n",
    "                        for ll, date_ll in enumerate(opp_prev_opp_prev_df['Date']):\n",
    "\n",
    "                            if date_ll >= date_check:\n",
    "                                opp_prev_opp_prev_result.append(opp_prev_opp_prev_df['Avg_Result'][ll])\n",
    "                                break\n",
    "                            elif ll == (len_opp_prev_opp_prev - 1):\n",
    "                                opp_prev_opp_prev_result.append(opp_prev_opp_prev_df['Avg_Result_Fin'][0])\n",
    "\n",
    "                    opp_prev_opp_prev_results.append(np.mean(opp_prev_opp_prev_result))\n",
    "                    \n",
    "                    # appends the average result of opponent's opponent's previous games\n",
    "                    opp_avg_results.append(opp_prev_avg_result)\n",
    "\n",
    "                    if kk <= 10:\n",
    "                        opp_sos_nc_games.append(opp_prev_avg_result)\n",
    "\n",
    "                # appends the average results of all opponent's previous opponents previous games\n",
    "                opp_sos.append(np.array(opp_avg_results).mean())\n",
    "                opp_sos_nc.append(np.array(opp_sos_nc_games).mean())\n",
    "                opp_prev_opp_sos.append(np.mean(opp_prev_opp_prev_results))\n",
    "            else:\n",
    "                opp_sos.append(np.nan)\n",
    "                opp_sos_nc.append(np.nan)\n",
    "                opp_prev_opp_sos.append(np.nan)\n",
    "\n",
    "        # Converts the opponents' data to a dataframe and then renames the columns to avoid duplication of column names and \n",
    "        # provide clarity as to what the different columns represent\n",
    "        opp_data_df = pd.DataFrame(opp_data, index = list(range(len(opp_data))))\n",
    "        \n",
    "        columns_dict = {'result': 'result2', 'Mean_Score': 'Mean_Score2', 'Opp_Avg_Score': 'Opp_Avg_Score2', 'Avg_Score': 'Avg_Score2',\n",
    "                        'Avg_Mean_Score': 'Avg_Mean_Score2', 'Avg_Result': 'Avg_Result2', 'Pct_Margin': 'Pct_Margin2', 'Home': 'Home2',\n",
    "                        'Away': 'Away2', 'Neutral': 'Neutral2', 'Date': 'Date2', 'Loc': 'Loc2', 'Opp_name': 'Opp_name2', 'Win': 'Win2',\n",
    "                        'Opp_score': 'Opp_score2', 'Score': 'Score2', 'Threes': 'Threes2', 'Opp_Threes': 'Opp_Threes2',\n",
    "                        'Avg_Threes': 'Avg_Threes2', 'Opp_Avg_Threes': 'Opp_Avg_Threes2', 'Game_Number': 'Game_Number2',\n",
    "                        'Avg_Result_Fin': 'Avg_Result_Fin2', 'Avg_Result_NC': 'Avg_Result_NC2', 'Opp_Avg_FG_Pct': 'Opp_Avg_FG_Pct2',\n",
    "                        'Avg_FG_Pct': 'Avg_FG_Pct2'}\n",
    "        \n",
    "        opp_data_df = opp_data_df.rename(columns = columns_dict)[list(columns_dict.values())]\n",
    "        \n",
    "        # Converts the strength of schedule lists to dataframes that can be appended\n",
    "        sos_df = pd.DataFrame()\n",
    "        sos_df['SOS'] = sos        # Strength of schedule using all previous opponents\n",
    "        sos_df['SOS_NC'] = sos_nc  # Strength of schedule using only non-conference opponentes (first 10 opponents)\n",
    "        sos_df['Opp_SOS'] = opp_sos # Opponent's SOS using all previous opponents\n",
    "        sos_df['Opp_SOS_NC'] = opp_sos_nc\n",
    "        sos_df['Prev_SOS'] = prev_sos\n",
    "        sos_df['SOS_Fin'] = [sos_df['SOS'][len(sos_df) - 1]] * len(sos_df) # column that contains the final SOS\n",
    "        sos_df['SOS_All'] = sos_all\n",
    "        sos_df['SOS_All_Fin'] = [sos_df['SOS_All'][len(sos_df) - 1]] * len(sos_df)\n",
    "        sos_df['Opp_Prev_SOS'] = opp_prev_opp_sos\n",
    "\n",
    "        opp_data_df['Scoring_Pace_Diff'] = (df['Avg_Mean_Score'] - opp_data_df['Avg_Mean_Score2'])/2\n",
    "\n",
    "        # Looks at the relative percentage of points scored and given up by 3-pointers and multiplies that\n",
    "        # by the factor of the oppponent\n",
    "        team_score = df['Avg_Threes'] * opp_data_df['Opp_Avg_Threes2']\n",
    "        opp_score = df['Opp_Avg_Threes'] * opp_data_df['Avg_Threes2']\n",
    "        opp_data_df['Matchup_Comp'] = team_score / (abs(team_score) ** 0.5) \n",
    "        opp_data_df['Opp_Matchup_Comp'] = opp_score / (abs(opp_score) ** 0.5) \n",
    "\n",
    "        # combines original dataframe with data from game opponents, SOS of team, and SOS of opponents\n",
    "        combined_df.append(pd.concat([df, opp_data_df, sos_df], axis = 1))\n",
    "\n",
    "        # saves dataframe\n",
    "        combined_df[ii].to_csv('./Team_Dataframes/' + year + '/Team_Combined/' + teams[ii] + '.csv', index = False)\n",
    "\n",
    "        if ii%20 == 0:\n",
    "            print(ii)\n",
    "    \n",
    "    pd.concat((combined_df)).to_csv('./Team_Dataframes/' + year + 'Combined.csv', index=False)\n",
    "    \n",
    "    # list of concatenated dataframes\n",
    "    return combined_df\n",
    "\n",
    "def plot_params(SEs, STDs, MSEs, CVs, pct_accs, avg_lin_coefss):\n",
    "    \n",
    "    plt.plot(list(range(len(STDs))), STDs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
