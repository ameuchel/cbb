{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, SimpleRNN, GRU, LSTM, Dense, Flatten, GlobalMaxPool1D, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "import CBB_Funcs as cbb_fun\n",
    "import pickle\n",
    "from playsound import playsound\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE LOADING ALL DATA\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'playsound' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-11793835f626>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'DONE LOADING ALL DATA'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 39\u001b[1;33m \u001b[0mplaysound\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'mixkit-intro-transition-1146.wav'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'playsound' is not defined"
     ]
    }
   ],
   "source": [
    "# Get team names and urls\n",
    "teams_source = pd.read_excel('Team_Source.xlsx', header=None, names=['2016', '2016_Teams', '2016 Conf', '2017', '2017_Teams', '2018', '2018_Teams',\n",
    "                                                                     '2019', '2019_Teams', '2020', '2020_Teams', '2021', '2021_Teams'])\n",
    "# select years to be processed\n",
    "years = ['2016', '2017', '2018', '2019']\n",
    "#years = ['2021']\n",
    "\n",
    "# Set data-gathering parameters\n",
    "load = True\n",
    "scrape_data = True\n",
    "\n",
    "# Initialize dataframe\n",
    "cbb_df = pd.DataFrame()\n",
    "\n",
    "# loop through each year to be looked at\n",
    "for yr in years:\n",
    "    if load:\n",
    "        sources, teams, team_dict = cbb_fun.get_logistics(teams_source, yr) # #urls and team names for that year\n",
    "        #combined_df = [pd.read_csv('./Team_Dataframes/' + yr + '/Team_Combined/' + teams[ii] + '.csv') for ii in range(len(teams))] # load pre-processing data into list of dataframes   \n",
    "#         with open('./Team_Dataframes/' + yr + '/Combined.pickle', 'rb') as f:\n",
    "#             combined_df = pickle.load(f)\n",
    "        combined_df = []\n",
    "        for ii in range(len(teams)):\n",
    "            with open('./Team_Dataframes/' + yr + '/Team_Combined/' + teams[ii] + '.pickle', 'rb') as f:\n",
    "                combined_df.append(pickle.load(f))\n",
    "        \n",
    "        cbb_df = pd.concat((cbb_df, pd.concat(combined_df))) # concatenate all dataframes to final output dataframe\n",
    "    else:\n",
    "        teams_df, teams, team_dict = cbb_fun.get_team_data(teams_source, yr, scrape_data=scrape_data) # grab data for each team during the 'yr'\n",
    "        combined_df, next_g = cbb_fun.combine_data(teams_df, team_dict, teams, year=yr) # process the data adding information about opponent and previous games\n",
    "        cbb_df = pd.concat((cbb_df, pd.concat((combined_df)))) # concatenate all dataframes to final output dataframe\n",
    "\n",
    "# if loading all years, save to final '.csv' file\n",
    "# not necesasry for model development\n",
    "if len(years) == 4:\n",
    "    cbb_df.to_csv('./Final_Dataframes/Teams_Combined.csv', index=False)\n",
    "\n",
    "print('DONE LOADING ALL DATA')\n",
    "playsound('mixkit-intro-transition-1146.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "744/744 [==============================] - 6s 7ms/step - loss: 1.0001 - val_loss: 0.9560\n",
      "Epoch 2/20\n",
      "744/744 [==============================] - 5s 7ms/step - loss: 0.9981 - val_loss: 0.9540\n",
      "Epoch 3/20\n",
      "744/744 [==============================] - 5s 7ms/step - loss: 0.9951 - val_loss: 0.9474\n",
      "Epoch 4/20\n",
      "744/744 [==============================] - 5s 7ms/step - loss: 0.9401 - val_loss: 0.8624\n",
      "Epoch 5/20\n",
      "744/744 [==============================] - 5s 7ms/step - loss: 0.8836 - val_loss: 0.8306\n",
      "Epoch 6/20\n",
      "744/744 [==============================] - 5s 7ms/step - loss: 0.7957 - val_loss: 0.7158\n",
      "Epoch 7/20\n",
      "744/744 [==============================] - 5s 7ms/step - loss: 0.7388 - val_loss: 0.6898\n",
      "Epoch 8/20\n",
      "744/744 [==============================] - 5s 7ms/step - loss: 0.7205 - val_loss: 0.6757\n",
      "Epoch 9/20\n",
      "744/744 [==============================] - 5s 7ms/step - loss: 0.7022 - val_loss: 0.6970\n",
      "Epoch 10/20\n",
      "744/744 [==============================] - 5s 6ms/step - loss: 0.6956 - val_loss: 0.6717\n",
      "Epoch 11/20\n",
      "744/744 [==============================] - 5s 7ms/step - loss: 0.6887 - val_loss: 0.6538\n",
      "Epoch 12/20\n",
      "744/744 [==============================] - 5s 7ms/step - loss: 0.6820 - val_loss: 0.6503\n",
      "Epoch 13/20\n",
      "744/744 [==============================] - 5s 6ms/step - loss: 0.6776 - val_loss: 0.6427\n",
      "Epoch 14/20\n",
      "744/744 [==============================] - 5s 6ms/step - loss: 0.6767 - val_loss: 0.6896\n",
      "Epoch 15/20\n",
      "744/744 [==============================] - 5s 7ms/step - loss: 0.6715 - val_loss: 0.6426\n",
      "Epoch 16/20\n",
      "744/744 [==============================] - 5s 6ms/step - loss: 0.6684 - val_loss: 0.6390\n",
      "Epoch 17/20\n",
      "744/744 [==============================] - 5s 7ms/step - loss: 0.6694 - val_loss: 0.6310\n",
      "Epoch 18/20\n",
      "744/744 [==============================] - 5s 7ms/step - loss: 0.6642 - val_loss: 0.6605\n",
      "Epoch 19/20\n",
      "744/744 [==============================] - 5s 7ms/step - loss: 0.6675 - val_loss: 0.6365\n",
      "Epoch 20/20\n",
      "744/744 [==============================] - 5s 6ms/step - loss: 0.6611 - val_loss: 0.6264\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split, cross_val_score, KFold, GridSearchCV, StratifiedKFold\n",
    "\n",
    "features = ['Avg_Result', 'Avg_Result2', 'Avg_Result_NC', 'Avg_Result_NC2', 'Home', 'Away', 'SOS', 'Opp_SOS', 'Prev_SOS', 'Opp_Prev_SOS',\n",
    "            'SOS_NC', 'Opp_SOS_NC', 'Opp_Avg_FG_Pct', 'Opp_Avg_FG_Pct2', 'Pct_Margin', 'Pct_Margin2', 'Home_Pct', 'Home_Pct2', 'Scoring_Pace_Diff']\n",
    "\n",
    "num_features = len(features)\n",
    "\n",
    "#data = cbb_df.dropna(subset=features)\n",
    "data = cbb_df[cbb_df['Game_Number'] > 9].dropna(subset=features)\n",
    "\n",
    "X = data[features]\n",
    "y = np.array(data['result'])\n",
    "\n",
    "scx = StandardScaler()\n",
    "scy = StandardScaler()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "\n",
    "\n",
    "Xsc = scx.fit_transform(X_train)\n",
    "ysc = scy.fit_transform(y_train.reshape(len(y_train), 1))\n",
    "\n",
    "\n",
    "## try autoregressive RNN model\n",
    "i = Input(shape = (num_features, 1))\n",
    "x = LSTM(5)(i)\n",
    "x = Dense(2)(x)\n",
    "model = Model(i, x)\n",
    "model.compile(\n",
    "    loss='mse',\n",
    "    optimizer=Adam(lr=0.001),\n",
    ")\n",
    "\n",
    "# train the RNN\n",
    "r = model.fit(\n",
    "    Xsc, ysc,\n",
    "    epochs = 20,\n",
    "    validation_data = (scx.transform(X_test), scy.transform(y_test.reshape(len(y_test), 1))),\n",
    ") # 147"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.97995186, 0.96482104]], dtype=float32)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, classification_report, accuracy_score\n",
    "# preds = scx.inverse_transform(model.predict(scx.transform(X_test)))\n",
    "# mean_squared_error(y_test, preds)\n",
    "a = [[ 2.06850771,  0.3177479 ,  1.45136205,  0.70824758, -0.9201095 ,\n",
    "        1.10973191, -0.25160416, -0.2157574 ,  0.74924119,  0.07368955,\n",
    "        0.32795591, -0.27213971, -1.01182599, -1.06641661,  1.95400245,\n",
    "        0.34674887,  0.21189576, -0.81423816,  1.54092282]]\n",
    "model.predict(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the loss\n",
    "plt.plot(r.history['loss'], label = 'loss')\n",
    "plt.plot(r.history['val_loss'], label = 'val_loss')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(Dataset):\n",
    "    \n",
    "    def __init__(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return self.X[index], self.y[index]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's build the above network\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, input_features, output_features):\n",
    "        super(Model, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_features, 5)\n",
    "        self.fc2 = nn.Linear(5,4)\n",
    "        self.fc3 = nn.Linear(4,3)\n",
    "        self.fc4 = nn.Linear(3,output_features)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.tanh = nn.Tanh()\n",
    "        \n",
    "    def forward(self, X):\n",
    "        out = self.fc1(X)\n",
    "        out = self.tanh(out)\n",
    "        out = self.fc2(out)\n",
    "        out = self.tanh(out)\n",
    "        out = self.fc3(out)\n",
    "        out = self.tanh(out)\n",
    "        out = self.fc4(out)\n",
    "        out = self.sigmoid(out)\n",
    "\n",
    "        return out\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "object.__new__() takes exactly one argument (the type to instantiate)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-a3bbe418fe06>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m \u001b[0mdataset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;31m# Load the data to your dataloader for both processing and shuffling\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\typing.py\u001b[0m in \u001b[0;36m__new__\u001b[1;34m(cls, *args, **kwds)\u001b[0m\n\u001b[0;32m    873\u001b[0m             \u001b[0mobj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__new__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    874\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 875\u001b[1;33m             \u001b[0mobj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__new__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    876\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    877\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: object.__new__() takes exactly one argument (the type to instantiate)"
     ]
    }
   ],
   "source": [
    "features = ['Avg_Result', 'Avg_Result2', 'Avg_Result_NC', 'Avg_Result_NC2', 'Home', 'Away', 'SOS', 'Opp_SOS', 'Prev_SOS', 'Opp_Prev_SOS',\n",
    "            'SOS_NC', 'Opp_SOS_NC', 'Opp_Avg_FG_Pct', 'Opp_Avg_FG_Pct2', 'Pct_Margin', 'Pct_Margin2', 'Home_Pct', 'Home_Pct2', 'Scoring_Pace_Diff']\n",
    "\n",
    "num_features = len(features)\n",
    "\n",
    "#data = cbb_df.dropna(subset=features)\n",
    "data = cbb_df[cbb_df['Game_Number'] > 9].dropna(subset=features)\n",
    "\n",
    "X = data[features]\n",
    "y = data['Win']\n",
    "\n",
    "# Feature Normalization. All features should have the same range of values\n",
    "sc = StandardScaler()\n",
    "X = sc.fit_transform(X)\n",
    "\n",
    "# Now we convert the arrays to PyTorch tensors\n",
    "X = torch.tensor(X)\n",
    "y = torch.tensor(list(y)).unsqueeze(1)\n",
    "\n",
    "dataset = Dataset(X,y)\n",
    "\n",
    "# Load the data to your dataloader for both processing and shuffling\n",
    "train_loader = torch.utils.data.DataLoader(dataset = dataset, \n",
    "                           batch_size = 32,\n",
    "                           shuffle = True)\n",
    "\n",
    "#Create the network (an object of the Net class)\n",
    "net = Model(num_features,1)\n",
    "#In Binary Cross Entropy: the inpout and output should have the same shape\n",
    "#size_average = True --> the losses are averaged over observations for each minibatch\n",
    "criterion = torch.nn.BCELoss(size_average = True)\n",
    "#criterion = torch.nn.MSELoss()\n",
    "#We will use SGD with momentum with a learning rate of 0.1\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr=0.1, momentum=0.9)\n",
    "\n",
    "# Training the Network\n",
    "epochs = 1\n",
    "accuracy = np.zeros((epochs,1))\n",
    "mse = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs = inputs.float()\n",
    "        labels = labels.float()\n",
    "        # Forward Propagation\n",
    "        outputs = net(inputs)\n",
    "        #Loss Calculation\n",
    "        loss = criterion(outputs, labels)\n",
    "        #print(Loss)\n",
    "        #Clear the gradient buffer (w <-- w - lr*gradient)\n",
    "        optimizer.zero_grad()\n",
    "        #Backprop\n",
    "        loss.backward()\n",
    "        #Update Weights\n",
    "        optimizer.step()\n",
    "        \n",
    "    # Accuracy Calculation\n",
    "    output = (outputs>0.5).float()\n",
    "    # (output == labels).sum() / output.shape\n",
    "    accuracy[epoch, 0] = (output == labels).float().mean()\n",
    "    \n",
    "    # Accuracy Calculation\n",
    "    mse.append((output == labels).float().mean())\n",
    "    \n",
    "    #Print Statistis\n",
    "    print(\"Epoch {}/{}, Loss: {:.3f}, Accuracy:   {:.3f}\".format(epoch+1, epochs, loss, accuracy[epoch,0]))\n",
    " \n",
    "plt.plot(list(range(epochs)), mse);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "744/744 [==============================] - 2s 3ms/step - loss: 0.9117 - val_loss: 0.8099\n",
      "Epoch 2/100\n",
      "744/744 [==============================] - 2s 3ms/step - loss: 0.7833 - val_loss: 0.7194\n",
      "Epoch 3/100\n",
      "744/744 [==============================] - 2s 3ms/step - loss: 0.7106 - val_loss: 0.6697\n",
      "Epoch 4/100\n",
      "744/744 [==============================] - 2s 3ms/step - loss: 0.6702 - val_loss: 0.6429\n",
      "Epoch 5/100\n",
      "744/744 [==============================] - 2s 3ms/step - loss: 0.6486 - val_loss: 0.6291\n",
      "Epoch 6/100\n",
      "744/744 [==============================] - 2s 3ms/step - loss: 0.6370 - val_loss: 0.6215\n",
      "Epoch 7/100\n",
      "744/744 [==============================] - 2s 3ms/step - loss: 0.6303 - val_loss: 0.6170\n",
      "Epoch 8/100\n",
      "744/744 [==============================] - 2s 3ms/step - loss: 0.6261 - val_loss: 0.6140\n",
      "Epoch 9/100\n",
      "744/744 [==============================] - 2s 3ms/step - loss: 0.6233 - val_loss: 0.6118\n",
      "Epoch 10/100\n",
      "744/744 [==============================] - 2s 3ms/step - loss: 0.6212 - val_loss: 0.6101\n",
      "Epoch 11/100\n",
      "744/744 [==============================] - 2s 3ms/step - loss: 0.6196 - val_loss: 0.6087\n",
      "Epoch 12/100\n",
      "744/744 [==============================] - 2s 3ms/step - loss: 0.6184 - val_loss: 0.6077\n",
      "Epoch 13/100\n",
      "744/744 [==============================] - 2s 3ms/step - loss: 0.6173 - val_loss: 0.6069\n",
      "Epoch 14/100\n",
      "744/744 [==============================] - 2s 3ms/step - loss: 0.6165 - val_loss: 0.6060\n",
      "Epoch 15/100\n",
      "744/744 [==============================] - 2s 3ms/step - loss: 0.6158 - val_loss: 0.6053\n",
      "Epoch 16/100\n",
      "744/744 [==============================] - 2s 3ms/step - loss: 0.6152 - val_loss: 0.6048\n",
      "Epoch 17/100\n",
      "744/744 [==============================] - 2s 3ms/step - loss: 0.6146 - val_loss: 0.6044\n",
      "Epoch 18/100\n",
      "744/744 [==============================] - 2s 3ms/step - loss: 0.6142 - val_loss: 0.6038\n",
      "Epoch 19/100\n",
      "744/744 [==============================] - 2s 3ms/step - loss: 0.6138 - val_loss: 0.6035\n",
      "Epoch 20/100\n",
      "744/744 [==============================] - 2s 3ms/step - loss: 0.6135 - val_loss: 0.6032\n",
      "Epoch 21/100\n",
      "744/744 [==============================] - 2s 3ms/step - loss: 0.6132 - val_loss: 0.6029\n",
      "Epoch 22/100\n",
      "744/744 [==============================] - 2s 3ms/step - loss: 0.6130 - val_loss: 0.6027\n",
      "Epoch 23/100\n",
      "744/744 [==============================] - 2s 3ms/step - loss: 0.6128 - val_loss: 0.6026\n",
      "Epoch 24/100\n",
      "744/744 [==============================] - 2s 3ms/step - loss: 0.6126 - val_loss: 0.6024\n",
      "Epoch 25/100\n",
      "744/744 [==============================] - 2s 3ms/step - loss: 0.6124 - val_loss: 0.6022\n",
      "Epoch 26/100\n",
      "744/744 [==============================] - 2s 3ms/step - loss: 0.6123 - val_loss: 0.6021\n",
      "Epoch 27/100\n",
      "744/744 [==============================] - 2s 3ms/step - loss: 0.6121 - val_loss: 0.6019\n",
      "Epoch 28/100\n",
      "744/744 [==============================] - 2s 3ms/step - loss: 0.6120 - val_loss: 0.6018\n",
      "Epoch 29/100\n",
      "744/744 [==============================] - 2s 3ms/step - loss: 0.6119 - val_loss: 0.6017\n",
      "Epoch 30/100\n",
      "744/744 [==============================] - 2s 3ms/step - loss: 0.6118 - val_loss: 0.6017\n",
      "Epoch 31/100\n",
      "744/744 [==============================] - 2s 3ms/step - loss: 0.6117 - val_loss: 0.6015\n",
      "Epoch 32/100\n",
      "744/744 [==============================] - 2s 3ms/step - loss: 0.6116 - val_loss: 0.6016\n",
      "Epoch 33/100\n",
      "744/744 [==============================] - 2s 3ms/step - loss: 0.6116 - val_loss: 0.6013\n",
      "Epoch 34/100\n",
      "744/744 [==============================] - 2s 3ms/step - loss: 0.6115 - val_loss: 0.6014\n",
      "Epoch 35/100\n",
      "744/744 [==============================] - 2s 3ms/step - loss: 0.6114 - val_loss: 0.6014\n",
      "Epoch 36/100\n",
      "744/744 [==============================] - 2s 3ms/step - loss: 0.6114 - val_loss: 0.6012\n",
      "Epoch 37/100\n",
      "744/744 [==============================] - 2s 3ms/step - loss: 0.6113 - val_loss: 0.6012\n",
      "Epoch 38/100\n",
      "744/744 [==============================] - 2s 3ms/step - loss: 0.6113 - val_loss: 0.6011\n",
      "Epoch 39/100\n",
      "744/744 [==============================] - 2s 3ms/step - loss: 0.6112 - val_loss: 0.6014\n",
      "Epoch 40/100\n",
      "744/744 [==============================] - 2s 3ms/step - loss: 0.6112 - val_loss: 0.6011\n",
      "Epoch 41/100\n",
      "744/744 [==============================] - 2s 3ms/step - loss: 0.6111 - val_loss: 0.6010\n",
      "Epoch 42/100\n",
      "744/744 [==============================] - 2s 3ms/step - loss: 0.6111 - val_loss: 0.6010\n",
      "Epoch 43/100\n",
      "744/744 [==============================] - 2s 3ms/step - loss: 0.6110 - val_loss: 0.6010\n",
      "Epoch 44/100\n",
      "744/744 [==============================] - 2s 3ms/step - loss: 0.6110 - val_loss: 0.6010\n",
      "Epoch 45/100\n",
      "744/744 [==============================] - 2s 3ms/step - loss: 0.6109 - val_loss: 0.6009\n",
      "Epoch 46/100\n",
      "744/744 [==============================] - 2s 3ms/step - loss: 0.6109 - val_loss: 0.6008\n",
      "Epoch 47/100\n",
      "744/744 [==============================] - 2s 3ms/step - loss: 0.6109 - val_loss: 0.6009\n",
      "Epoch 48/100\n",
      "744/744 [==============================] - 2s 3ms/step - loss: 0.6108 - val_loss: 0.6007\n",
      "Epoch 49/100\n",
      "744/744 [==============================] - 2s 3ms/step - loss: 0.6108 - val_loss: 0.6008\n",
      "Epoch 50/100\n",
      "744/744 [==============================] - 2s 3ms/step - loss: 0.6108 - val_loss: 0.6007\n",
      "Epoch 51/100\n",
      "744/744 [==============================] - 2s 3ms/step - loss: 0.6107 - val_loss: 0.6008\n",
      "Epoch 52/100\n",
      "744/744 [==============================] - 2s 3ms/step - loss: 0.6107 - val_loss: 0.6006\n",
      "Epoch 53/100\n",
      "744/744 [==============================] - 2s 3ms/step - loss: 0.6107 - val_loss: 0.6007\n",
      "Epoch 54/100\n",
      "744/744 [==============================] - 2s 3ms/step - loss: 0.6106 - val_loss: 0.6006\n",
      "Epoch 55/100\n",
      "744/744 [==============================] - 2s 3ms/step - loss: 0.6106 - val_loss: 0.6005\n",
      "Epoch 56/100\n",
      "744/744 [==============================] - 2s 3ms/step - loss: 0.6106 - val_loss: 0.6005\n",
      "Epoch 57/100\n",
      "744/744 [==============================] - 2s 3ms/step - loss: 0.6105 - val_loss: 0.6005\n",
      "Epoch 58/100\n",
      "744/744 [==============================] - 2s 3ms/step - loss: 0.6105 - val_loss: 0.6005\n",
      "Epoch 59/100\n",
      "744/744 [==============================] - 2s 3ms/step - loss: 0.6105 - val_loss: 0.6005\n",
      "Epoch 60/100\n",
      "744/744 [==============================] - 2s 3ms/step - loss: 0.6104 - val_loss: 0.6004\n",
      "Epoch 61/100\n",
      "744/744 [==============================] - 2s 3ms/step - loss: 0.6104 - val_loss: 0.6004\n",
      "Epoch 62/100\n",
      "744/744 [==============================] - 2s 3ms/step - loss: 0.6104 - val_loss: 0.6005\n",
      "Epoch 63/100\n",
      "744/744 [==============================] - 2s 3ms/step - loss: 0.6104 - val_loss: 0.6005\n",
      "Epoch 64/100\n",
      "744/744 [==============================] - 2s 3ms/step - loss: 0.6104 - val_loss: 0.6004\n",
      "Epoch 65/100\n",
      "744/744 [==============================] - 2s 3ms/step - loss: 0.6103 - val_loss: 0.6003\n",
      "Epoch 66/100\n",
      "744/744 [==============================] - 2s 3ms/step - loss: 0.6103 - val_loss: 0.6003\n",
      "Epoch 67/100\n",
      "744/744 [==============================] - 2s 3ms/step - loss: 0.6103 - val_loss: 0.6003\n",
      "Epoch 68/100\n",
      "744/744 [==============================] - 2s 3ms/step - loss: 0.6103 - val_loss: 0.6002\n",
      "Epoch 69/100\n",
      "744/744 [==============================] - 2s 3ms/step - loss: 0.6102 - val_loss: 0.6003\n",
      "Epoch 70/100\n",
      "744/744 [==============================] - 2s 3ms/step - loss: 0.6102 - val_loss: 0.6002\n",
      "Epoch 71/100\n",
      "744/744 [==============================] - 2s 3ms/step - loss: 0.6102 - val_loss: 0.6002\n",
      "Epoch 72/100\n",
      "744/744 [==============================] - 2s 3ms/step - loss: 0.6102 - val_loss: 0.6002\n",
      "Epoch 73/100\n",
      "744/744 [==============================] - 2s 3ms/step - loss: 0.6101 - val_loss: 0.6003\n",
      "Epoch 74/100\n",
      "744/744 [==============================] - 2s 3ms/step - loss: 0.6101 - val_loss: 0.6001\n",
      "Epoch 75/100\n",
      "744/744 [==============================] - 2s 3ms/step - loss: 0.6101 - val_loss: 0.6001\n",
      "Epoch 76/100\n",
      "744/744 [==============================] - 2s 3ms/step - loss: 0.6101 - val_loss: 0.6001\n",
      "Epoch 77/100\n",
      "744/744 [==============================] - 2s 3ms/step - loss: 0.6100 - val_loss: 0.6001\n",
      "Epoch 78/100\n",
      "744/744 [==============================] - 2s 3ms/step - loss: 0.6100 - val_loss: 0.6001\n",
      "Epoch 79/100\n",
      "744/744 [==============================] - 2s 3ms/step - loss: 0.6100 - val_loss: 0.6000\n",
      "Epoch 80/100\n",
      "744/744 [==============================] - 2s 3ms/step - loss: 0.6100 - val_loss: 0.6000\n",
      "Epoch 81/100\n",
      "744/744 [==============================] - 2s 3ms/step - loss: 0.6100 - val_loss: 0.6001\n",
      "Epoch 82/100\n",
      "744/744 [==============================] - 2s 3ms/step - loss: 0.6100 - val_loss: 0.6000\n",
      "Epoch 83/100\n",
      "744/744 [==============================] - 2s 3ms/step - loss: 0.6099 - val_loss: 0.6001\n",
      "Epoch 84/100\n",
      "744/744 [==============================] - 2s 3ms/step - loss: 0.6099 - val_loss: 0.5999\n",
      "Epoch 85/100\n",
      "744/744 [==============================] - 2s 3ms/step - loss: 0.6099 - val_loss: 0.6001\n",
      "Epoch 86/100\n",
      "744/744 [==============================] - 2s 3ms/step - loss: 0.6099 - val_loss: 0.6000\n",
      "Epoch 87/100\n",
      "744/744 [==============================] - 2s 3ms/step - loss: 0.6099 - val_loss: 0.6001\n",
      "Epoch 88/100\n",
      "744/744 [==============================] - 2s 3ms/step - loss: 0.6099 - val_loss: 0.5999\n",
      "Epoch 89/100\n",
      "744/744 [==============================] - 2s 3ms/step - loss: 0.6098 - val_loss: 0.6000\n",
      "Epoch 90/100\n",
      "744/744 [==============================] - 2s 3ms/step - loss: 0.6098 - val_loss: 0.5999\n",
      "Epoch 91/100\n",
      "744/744 [==============================] - 2s 3ms/step - loss: 0.6098 - val_loss: 0.5999\n",
      "Epoch 92/100\n",
      "744/744 [==============================] - 2s 3ms/step - loss: 0.6098 - val_loss: 0.5999\n",
      "Epoch 93/100\n",
      "744/744 [==============================] - 2s 3ms/step - loss: 0.6098 - val_loss: 0.5999\n",
      "Epoch 94/100\n",
      "744/744 [==============================] - 2s 3ms/step - loss: 0.6098 - val_loss: 0.6000\n",
      "Epoch 95/100\n",
      "744/744 [==============================] - 2s 3ms/step - loss: 0.6098 - val_loss: 0.5999\n",
      "Epoch 96/100\n",
      "744/744 [==============================] - 2s 3ms/step - loss: 0.6097 - val_loss: 0.5999\n",
      "Epoch 97/100\n",
      "744/744 [==============================] - 2s 3ms/step - loss: 0.6097 - val_loss: 0.5999\n",
      "Epoch 98/100\n",
      "744/744 [==============================] - 2s 3ms/step - loss: 0.6097 - val_loss: 0.5999\n",
      "Epoch 99/100\n",
      "744/744 [==============================] - 2s 3ms/step - loss: 0.6097 - val_loss: 0.5997\n",
      "Epoch 100/100\n",
      "744/744 [==============================] - 2s 3ms/step - loss: 0.6097 - val_loss: 0.5997\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "121.29172069683209"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = ['Avg_Result', 'Avg_Result2', 'Avg_Result_NC', 'Avg_Result_NC2', 'Home', 'Away', 'SOS', 'Opp_SOS', 'Prev_SOS', 'Opp_Prev_SOS',\n",
    "            'SOS_NC', 'Opp_SOS_NC', 'Opp_Avg_FG_Pct', 'Opp_Avg_FG_Pct2', 'Pct_Margin', 'Pct_Margin2', 'Home_Pct', 'Home_Pct2', 'Scoring_Pace_Diff']\n",
    "\n",
    "num_features = len(features)\n",
    "\n",
    "#data = cbb_df.dropna(subset=features)\n",
    "data = cbb_df[cbb_df['Game_Number'] > 9].dropna(subset=features)\n",
    "\n",
    "X = data[features]\n",
    "y = np.array(data['result'])\n",
    "\n",
    "# Feature Normalization. All features should have the same range of values\n",
    "scx = StandardScaler()\n",
    "scy = StandardScaler()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "\n",
    "X_sc = scx.fit_transform(X_train)\n",
    "y_sc = scy.fit_transform(y_train.reshape(len(y_train), 1))\n",
    "\n",
    "# # Try a linear model first - note: it is classification now!\n",
    "# i = Input(shape=(num_features,2))\n",
    "# x = Dense(2, activation = 'sigmoid')(i)\n",
    "# model = Model(i,x)\n",
    "# model.compile(\n",
    "#     loss = 'binary_crossentropy',\n",
    "#     optimizer = Adam(lr=0.01),\n",
    "#     metrics = ['accuracy'],\n",
    "# )\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    Flatten(input_shape=(num_features,)),\n",
    "    Dense(2096),\n",
    "    Dense(24),\n",
    "    Dense(1)\n",
    "])\n",
    "\n",
    "model.compile(optimizer=Adam(lr=0.0000005), loss='mse')\n",
    "\n",
    "# train the network\n",
    "r = model.fit(\n",
    "    X_sc, y_sc,\n",
    "    epochs=100,\n",
    "    validation_data = (scx.transform(X_test), scy.transform(y_test.reshape(len(y_test), 1))),\n",
    ")\n",
    "\n",
    "predictions = model.predict(scx.transform(X_test))\n",
    "predictions = scy.inverse_transform(predictions)\n",
    "mean_squared_error(y_test, predictions) # 0.5997 val-loss, 100 epochs, lr=0.0000005, mse = 121.29172069683209"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'val_loss'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-140-920d9dc73f69>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#Plot the loss\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'loss'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'loss'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'val_loss'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'val_loss'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'val_loss'"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Plot the loss\n",
    "plt.plot(r.history['loss'], label = 'loss')\n",
    "plt.plot(r.history['val_loss'], label = 'val_loss')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((31732, 12), (31732, 12))"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = sc.fit_transform(X, y)\n",
    "a.shape, X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForest MSE: 131.22192644648933\n"
     ]
    }
   ],
   "source": [
    "sc = StandardScaler()\n",
    "X = sc.fit_transform(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "\n",
    "model = RandomForestRegressor(n_estimators=100)\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print('RandomForest MSE:', mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((31732, 12), (31732, 1))"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, y.reshape(len(y), 1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost MSE: 127.08801837597234\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "xgbmodel = XGBRegressor(n_estimators=20)\n",
    "xgbmodel.fit(X_train, y_train, verbose=False)\n",
    "\n",
    "y_pred = xgbmodel.predict(X_test)\n",
    "mse = mean_squared_error(y_pred, y_test)\n",
    "print('XGBoost MSE:', mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "def running_means(scores, opp_scores, mean_scores, threes, opp_threes, fg_pct, opp_fg_pct):\n",
    "    \"\"\"\n",
    "        Function takes in (scores, opp_scores) which are lists of a team's scores\n",
    "        and the scores of its opponents. The function returns two lists which \n",
    "        are the running means of the team and the team's previous opponents.\n",
    "    \"\"\"\n",
    "    \n",
    "    # 'means' and opp_means are initialized with a NaN value because there is no\n",
    "    # previous data to grab before the first game\n",
    "    means = [np.nan]\n",
    "    opp_means = [np.nan]\n",
    "    avg_mean_scores = [np.nan]\n",
    "    avg_threes = [np.nan]\n",
    "    avg_opp_threes = [np.nan]\n",
    "    avg_fg_pct = [np.nan]\n",
    "    avg_opp_fg_pct = [np.nan]\n",
    "    \n",
    "    # loops through each score and opponent score beginning with game 2\n",
    "    for idx, (score, opp_score)  in enumerate(zip(scores[1:], opp_scores[1:])):\n",
    "        \n",
    "        # appends the running means\n",
    "        means.append(scores[:idx+1].mean())\n",
    "        opp_means.append(opp_scores[:idx+1].mean())\n",
    "        avg_mean_scores.append(mean_scores[:idx+1].mean())\n",
    "        avg_fg_pct.append(fg_pct[:idx+1].mean())\n",
    "        avg_opp_fg_pct.append(opp_fg_pct[:idx+1].mean())\n",
    "        \n",
    "        # calculates percentage of points scored and given up by threes and then substracts the pre-calculated league average\n",
    "        avg_threes.append(((threes[:idx+1]*3).mean() / means[idx+1]) - threes_pct)\n",
    "        avg_opp_threes.append(((opp_threes[:idx+1]*3).mean() / opp_means[idx+1]) - threes_pct) \n",
    "\n",
    "    return means, opp_means, avg_mean_scores, avg_threes, avg_opp_threes, avg_fg_pct, avg_opp_fg_pct\n",
    "\n",
    "def get_logistics(year):\n",
    "    # Grabs logistical data about the college basketball teams\n",
    "    sources = teams_source[year].dropna()                  # website sources for each team\n",
    "    teams = teams_source[year + '_Teams'].dropna()         # names of teams \n",
    "    team_nums = list(range(len(teams))) # idx numbers for each team\n",
    "    team_dict = {teams[num]: num for num in team_nums}\n",
    "    \n",
    "    return year, sources, teams, team_dict\n",
    "\n",
    "def get_linear_stats(X, y, n_runs=10, n_folds=10):\n",
    "    \"\"\"\n",
    "        Takes in X and y data and returns Linear Model statistics.\n",
    "        Returns Standard Error, Standard Deviation, Mean Squared Error,\n",
    "        Cross-Validation Score, and statsmodels OLS results.\n",
    "        \n",
    "        n_runs is the number of training runs to perform. An increase in n_runs\n",
    "        provides more stable results.\n",
    "        \n",
    "        n_folds is the number of folds to create in the cross-validation test\n",
    "    \"\"\"\n",
    "    \n",
    "    # Initialized Linear Regression model\n",
    "    lr = LinearRegression()\n",
    "    \n",
    "    # drops null values from data input\n",
    "    X = X.dropna()\n",
    "    y = y.dropna()\n",
    "    \n",
    "    # number for features in model\n",
    "    num_features = X.shape[1]\n",
    "    \n",
    "    # initializes statistics that will be averaged\n",
    "    MSEs = []\n",
    "    SE = []\n",
    "    stds = []\n",
    "    scores = []\n",
    "    pct_acc = []\n",
    "    cv = []\n",
    "    coefs = []\n",
    "    \n",
    "    # Number of training runs\n",
    "    # Increase in runs stabilizes results\n",
    "    for ii in range(n_runs):\n",
    "        \n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "\n",
    "        lr.fit_intercept = False\n",
    "        lr.fit(X_train, y_train)\n",
    "\n",
    "        y_pred = lr.predict(X_test)\n",
    "        \n",
    "        # Difference between predicted results and test data\n",
    "        resid = y_pred - y_test\n",
    "        \n",
    "        # Append statistics\n",
    "        SE.append(np.std(resid, ddof=num_features) / np.sqrt(np.size(resid)))\n",
    "        stds.append(np.std(resid, ddof=num_features))\n",
    "        MSEs.append(mean_squared_error(y_test, y_pred))\n",
    "        scores.append(lr.score(X_test, y_test))\n",
    "        \n",
    "         # Show percent accuracy of predicting win/loss\n",
    "        num_correct = 0\n",
    "        for pred, act in zip(y_pred, y_test):\n",
    "            if pred*act > 0:\n",
    "                num_correct += 1\n",
    "        pct_acc.append(num_correct/len(y_test))\n",
    "        \n",
    "        coefs.append(lr.coef_)\n",
    "        \n",
    "        cv.append(cross_val_score(LinearRegression(), X, y, cv=KFold(n_folds, shuffle=True)).mean())\n",
    "   \n",
    "    \n",
    "    # Develop OLS model\n",
    "    model = sm.OLS(y_train, X_train, missing = 'drop') # sm.add_constant(X)\n",
    "    results = model.fit()\n",
    "    \n",
    "    return np.mean(SE), np.mean(stds), np.mean(MSEs), np.mean(cv), results, np.mean(pct_acc)*100, np.mean(coefs, axis=0)\n",
    "\n",
    "def get_logistic_stats(X, y, n_runs=10, n_folds=10):\n",
    "    \"\"\"\n",
    "        Takes in X and y data and returns Logistic Model statistics.\n",
    "        Returns Percent Accuracy.\n",
    "        \n",
    "        n_runs is the number of training runs to perform. An increase in n_runs\n",
    "        provides more stable results.\n",
    "        \n",
    "        n_folds is the number of folds to create in the cross-validation test\n",
    "    \"\"\"\n",
    "\n",
    "    # drops null values from data input\n",
    "    X = X.dropna()\n",
    "    y = y.dropna()\n",
    "    \n",
    "    sc = StandardScaler()\n",
    "    X = sc.fit_transform(X)\n",
    "\n",
    "    # Initialized Logistic Regression model\n",
    "    lr = LogisticRegression(max_iter=1000)\n",
    "    \n",
    "    # initializes statistics that will be averaged\n",
    "    cv = []\n",
    "    coefs = []\n",
    "    \n",
    "    # Number of training runs\n",
    "    # Increase in runs stabilizes results\n",
    "    for ii in range(n_runs):\n",
    "        \n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "\n",
    "        lr.fit(X_train, y_train)\n",
    "\n",
    "        coefs.append(lr.coef_)\n",
    "        \n",
    "        cv.append(cross_val_score(LogisticRegression(max_iter=1000), X, y, cv=KFold(n_folds, shuffle=True)).mean())\n",
    "    \n",
    "    return np.mean(cv)*100, np.mean(coefs, axis=0)\n",
    "\n",
    "def webscrape_data(year, sources, teams):\n",
    "    dataframes = [] # list of dataframes\n",
    "\n",
    "    # Loops through each team listed in the sources list of urls\n",
    "    for ii, src in enumerate(sources):\n",
    "        content = urllib.request.urlopen(src) # opens content of url\n",
    "        read_content = content.read()   # reads content\n",
    "\n",
    "        soup = BeautifulSoup(read_content,'html.parser')  # pass the content to BeautifulSoup to parse\n",
    "        tags = soup.find_all('td') # grab only tags with 'td' which grabs the data table from the website\n",
    "\n",
    "        data = []\n",
    "        row = []\n",
    "        # loops through extracted tag\n",
    "        for idx, tr in enumerate(tags):\n",
    "            row.append(tr.text) # appends text of the tag\n",
    "\n",
    "            # Given that there are 39 columns of data in the table,\n",
    "            # a check is perfromed on if the tag is the last tag\n",
    "            # in the row\n",
    "            if (idx + 1)%39 == 0: \n",
    "\n",
    "                # if the opponent team name ('idx 3'), does not an 'a' href,\n",
    "                # then that team is not a Division 1 school and will not have \n",
    "                # data of its own in the dataframe. Because the program will use\n",
    "                # data from the opponent, all data from non-Division 1 schools\n",
    "                # is removed.\n",
    "                if tags[idx - 36].find('a'):\n",
    "                    data.append(row) # row of data is appended to data list if opponent is Division 1\n",
    "                row = []\n",
    "\n",
    "        # Removes cancelled game between Hampton and Morgan State\n",
    "        # Score was 2-0 at the time of cancellation\n",
    "        if (year == '2018') and ((ii == 112) or (ii == 191)):\n",
    "            if ii == 112:\n",
    "                data = data[:26] + data[27:]\n",
    "            else:\n",
    "                data = data[:24] + data[25:]\n",
    "\n",
    "        # dataframe is created and key columns are renamed to better represent the data\n",
    "        df = pd.DataFrame(data).rename(columns = {0: 'Date', 1: 'Loc', 2: 'Opp_name', 3: 'Win', 4: 'Score', 5: 'Opp_score', 8: 'FG_Pct', 9:'Threes', 25: 'Opp_FG_Pct', 9:'Threes', 26: 'Opp_Threes'})\n",
    "\n",
    "        # datatypes of numerical columns are changed to floats \n",
    "        try:\n",
    "            df = df.astype({key: float for key in df.keys() if key not in ['Date', 'Loc', 'Opp_name', 'Win', 22]})\n",
    "        except ValueError: # handles value errors (by looking through the data it was determined there are a few instances where a cell was left blank)\n",
    "            for col in df: # iterates through each column in dataframe\n",
    "                float_vals = []\n",
    "                for val in df[col]: # iterates through each value in column\n",
    "                    try:\n",
    "                        float_vals.append(float(val)) # converts to float if possible\n",
    "                    except ValueError:   # used for values that cannot be converted to float\n",
    "                        if col not in ['Date', 'Loc', 'Opp_name', 'Win', 22]:  # checks to make sure it wasn't supposed to be a String\n",
    "                            float_vals.append(np.nan) # replace blank space with NaN\n",
    "                        else:\n",
    "                            float_vals.append(val) # leaves value as is\n",
    "\n",
    "                df[col] = pd.Series(float_vals) # replaces column with new \"float_values\"\n",
    "\n",
    "        # Convert 'Date' to datetime for evaluation later in runtime\n",
    "        df['Date'] = pd.to_datetime(df['Date'])\n",
    "\n",
    "        # The result column is added which represents how much the team lost or won by in that game\n",
    "        # This will be the y-vector that the prediction model uses.\n",
    "        df['result'] = df['Score'] - df['Opp_score']\n",
    "        \n",
    "        # The 'Win' column is 1 if the team won the game and 0 otherwise.\n",
    "        # This will be another y-vector that the model predicts\n",
    "        df['Win'] = np.where(df['result'] > 0, 1, 0)\n",
    "\n",
    "        # Keep track of the Game Number\n",
    "        df['Game_Number'] = list(range(1, len(df) + 1))\n",
    "\n",
    "        # Calcultes the mean score of each game ( (team_score + opp_score) / 2 )\n",
    "        df['Mean_Score'] = df[['Score', 'Opp_score']].mean(axis = 1)\n",
    "\n",
    "        # Columns that represent the average scores of both the team and team's previous opponents\n",
    "        # are added to the dataframe. This is done by calling the \"running_means\" function.\n",
    "        # The data represents the averages going into the game\n",
    "        df['Avg_Score'], df['Opp_Avg_Score'], df['Avg_Mean_Score'], df['Avg_Threes'], df['Opp_Avg_Threes'], df['Avg_FG_Pct'], df['Opp_Avg_FG_Pct'] = \\\n",
    "        running_means(df['Score'], df['Opp_score'], df['Mean_Score'], df['Threes'], df['Opp_Threes'], df['FG_Pct'], df['Opp_FG_Pct'])\n",
    "\n",
    "        # Calculates the average value of vicotry/loss\n",
    "        df['Avg_Result'] = df['Avg_Score'] - df['Opp_Avg_Score']\n",
    "\n",
    "        # Calculates the percent margin of victory/loss as percentage of mean scores\n",
    "        df['Pct_Margin'] = df['Avg_Result'] / df['Avg_Mean_Score']\n",
    "\n",
    "        # Create Dummy Variables for Home and Away\n",
    "        location = pd.get_dummies(df['Loc'])\n",
    "        if location.shape[1] == 3:\n",
    "            location.columns = ['Home', 'Away', 'Neutral']\n",
    "        else: # needed for teams that don't have any neutral-site games\n",
    "            location.columns = ['Home', 'Away']   \n",
    "\n",
    "        # concatenate original dataframe to new location dummy dataframe\n",
    "        df = pd.concat((df, location), axis = 1)\n",
    "\n",
    "        # create a column that contains the average season result in every row\n",
    "        df['Avg_Result_Fin'] = [df['Score'].mean() - df['Opp_score'].mean()] * len(df)\n",
    "\n",
    "        # Create a column that contains just the average result from non-conference games (first 10 games)\n",
    "        df['Avg_Result_NC'] = list(df['Avg_Result'][:10]) + [df['Avg_Result'][9]] * (len(df) - 10)\n",
    "\n",
    "        # saves dataframe\n",
    "        df.to_csv('./Team_Dataframes/' + year + '/Team_Only/' + teams[ii] + '.csv', index = False)\n",
    "\n",
    "        # add dataframe to list of dataframes\n",
    "        dataframes.append(df)\n",
    "    \n",
    "    print('DONE WITH DATA INTAKE', year)\n",
    "    return dataframes\n",
    "\n",
    "def load_frames(teams=[], year='2016', multiple=False):\n",
    "    \n",
    "    if multiple:\n",
    "        \n",
    "        dataframes = pd.read_csv('./Final_Dataframes/Teams_Only.csv')\n",
    "        \n",
    "        dataframes['Date'] = pd.to_datetime(dataframes['Date'])\n",
    "    \n",
    "    else:\n",
    "        \n",
    "        dataframes = [pd.read_csv('./Team_Dataframes/' + year + '/Team_Only/' + teams[ii] + '.csv') for ii in range(len(teams))]\n",
    "\n",
    "        for df in dataframes:\n",
    "\n",
    "            # Convert 'Date' to datetime for evaluation later in runtime\n",
    "            df['Date'] = pd.to_datetime(df['Date'])\n",
    "    \n",
    "    print('DONE LOADING FRAMES')\n",
    "    \n",
    "    return dataframes\n",
    "\n",
    "# Grabs logistical data about the college basketball teams\n",
    "def get_team_data(year='2016', multiple=False, scrape_data=False):\n",
    "    \"\"\"\n",
    "       Returns team-specific data. Default arguments (year='2016', multiple=False, scrape_data=False).\n",
    "       'year' specificies which year of data to collect.\n",
    "       'multiple' will return only the 'year' of data when set to False, but will return all years when set to True\n",
    "       'scrape_data' will load existing data if set to False, but will scrape data from the web if set to True\n",
    "    \"\"\"\n",
    "\n",
    "    if multiple:\n",
    "\n",
    "        years = ['2016', '2017', '2018', '2019']\n",
    "\n",
    "        ## run if scraping new data\n",
    "        if scrape_data:\n",
    "\n",
    "            tot_frame = []\n",
    "\n",
    "            for year in years:\n",
    "\n",
    "                # grab logistical data such as web sources and team names\n",
    "                year, sources, teams, team_dict = get_logistics(year)\n",
    "                dataframes = webscrape_data(year, sources, teams)\n",
    "                tot_frame.append(pd.concat((dataframes)))\n",
    "\n",
    "            tot_frame = pd.concat((tot_frame))\n",
    "            tot_frame.to_csv('./Final_Dataframes/Teams_Only.csv', index=False)\n",
    "\n",
    "        ## run if loading existing \n",
    "        else:\n",
    "\n",
    "            tot_frame = load_frames(multiple=True)\n",
    "            \n",
    "        return tot_frame, '', ''\n",
    "\n",
    "    else:\n",
    "\n",
    "        year, sources, teams, team_dict = get_logistics(year)\n",
    "\n",
    "        ## run if scraping new data\n",
    "        if scrape_data:\n",
    "\n",
    "            dataframes = webscrape_data(year, sources, teams)\n",
    "\n",
    "        ## run if loading existing \n",
    "        else:\n",
    "\n",
    "            dataframes = load_frames(teams=teams, year=year)\n",
    "\n",
    "        return dataframes, teams, team_dict\n",
    "    \n",
    "def combine_data(dataframes, team_dict, teams, year='2016'):\n",
    "    \"\"\"\n",
    "    Takes in a list of dataframes\n",
    "    Function looks at team's opponents' dataframes and concatenates the team's dataframe\n",
    "    with data from the opponents.\n",
    "    Returns a list of concatenated dataframes for each team\n",
    "    \"\"\"\n",
    "    \n",
    "    # Initialize a list of dataframes that will combine a team's dataframe with data from its opponents\n",
    "    combined_df = []\n",
    "\n",
    "    # loop through each dataframe (team)\n",
    "    for ii, df in enumerate(dataframes):\n",
    "\n",
    "        # initialize a list that will represent the strength of schedule of the team entering the game\n",
    "        # initialized with NaN because there would be no previous opponents entering the first game\n",
    "        sos = [np.nan]\n",
    "        sos_all = [np.nan] # uses final average result from each previous opponent\n",
    "        sos_nc = [np.nan] # team's non-conference SOS\n",
    "\n",
    "        # initialize a list that will represent the strength of schedule of the team's previous opponents\n",
    "        # entering the game\n",
    "        # initialized with NaN because there would be no previous opponents entering the first game\n",
    "        prev_sos = [np.nan]\n",
    "        prev_sos_all = [np.nan] # uses final average result from each previous opponent\n",
    "        prev_sos_nc = [np.nan] # team's non-conference SOS\n",
    "\n",
    "        # Initializes a list that will represent the strength of schedule of the opponent entering the game\n",
    "        # This list is not initialized with NaN because the opponent may have already played a game before\n",
    "        # the team's first game\n",
    "        opp_sos =[]\n",
    "        opp_sos_nc = []\n",
    "        opp_prev_opp_sos = []\n",
    "\n",
    "        # list that will contain data of opponent\n",
    "        opp_data = []\n",
    "\n",
    "        # names of all opponents\n",
    "        opp_names = df['Opp_name']\n",
    "        \n",
    "        name_check = teams[ii]\n",
    "\n",
    "        # loops through every game, specifically by enumerating the opponent name column\n",
    "        for idx, name in enumerate(opp_names):\n",
    "            \n",
    "            date_check = df['Date'][idx]\n",
    "            \n",
    "            # will loop through each team's opponent prior to current game\n",
    "            # first checks if idx is greater than 0 because there are no games\n",
    "            # before the first game\n",
    "            if idx > 0:\n",
    "                \n",
    "                # list of all previous opponents\n",
    "                prev_opps = opp_names[:idx]\n",
    "\n",
    "                # list that will store average win/loss results for each previous opponent\n",
    "                avg_results = []\n",
    "                sos_all_results = [] # stores the final average score for each previous opponent\n",
    "                sos_nc_games = []\n",
    "\n",
    "                # lists that will store average win/loss results for each previous opponent's previous opponents\n",
    "                prev_prev_avg_results = []\n",
    "                prev_sos_all_results = []\n",
    "                prev_sos_nc_games = []\n",
    "\n",
    "                # loop through each previous opponent\n",
    "                for jj, prev_name in enumerate(prev_opps):\n",
    "                    # previous opponent dataframe\n",
    "                    prev_df = dataframes[team_dict[prev_name]]\n",
    "                    \n",
    "                    len_prev = len(prev_df)\n",
    "\n",
    "                    # loops through each game for previous opponent\n",
    "                    for idx3, date2 in enumerate(prev_df['Date']):\n",
    "                        if date2 >= date_check:\n",
    "                            prev_avg_result = prev_df['Avg_Result'][idx3]\n",
    "                            prev_opp_prev = prev_df['Opp_name'][:idx3]\n",
    "                            break\n",
    "                        elif idx3 == (len_prev - 1):\n",
    "                            prev_avg_result = prev_df['Avg_Result_Fin'][0]\n",
    "                            prev_opp_prev = prev_df['Opp_name']\n",
    "                            break     \n",
    "\n",
    "                    ## Only grabs index <= 10 as that is about how many pre-conference\n",
    "                    ## games each team plays\n",
    "                    if jj <= 10:\n",
    "                        sos_nc_games.append(prev_avg_result)\n",
    "\n",
    "                    ## append strength of schedule data\n",
    "                    avg_results.append(prev_avg_result)\n",
    "                    sos_all_results.append(prev_df['Avg_Result_Fin'][0])\n",
    "\n",
    "                    # loops through the previous opponents of the previous opponent\n",
    "                    # to find the SOS of previous opponents\n",
    "                    for prev_opp in prev_opp_prev:\n",
    "                        prev2_df = dataframes[team_dict[prev_opp]]\n",
    "                        \n",
    "                        len_prev2 = len(prev2_df)\n",
    "\n",
    "                        for kk, date_kk in enumerate(prev2_df['Date']):\n",
    "                            if date_kk >= date_check:\n",
    "                                #prev_prev_avg_result = prev2_df['result'][:kk].mean()\n",
    "                                prev_prev_avg_result = prev2_df['Avg_Result'][kk]\n",
    "                                break\n",
    "                            elif kk == (len_prev2 - 1):\n",
    "                                #prev_prev_avg_result = prev2_df['result'].mean()\n",
    "                                prev_prev_avg_result = prev2_df['Avg_Result_Fin'][0]\n",
    "                                break   \n",
    "\n",
    "                        ## Only grabs index <= 10 as that is about how many pre-conference\n",
    "                        ## games each team plays\n",
    "                        if kk <= 10:\n",
    "                            prev_sos_nc_games.append(prev_prev_avg_result)\n",
    "\n",
    "                        ## append strength of schedule data\n",
    "                        prev_prev_avg_results.append(prev_prev_avg_result)\n",
    "                        prev_sos_all_results.append(prev2_df['Avg_Result_Fin'][0])\n",
    "\n",
    "                # take means of SOS data to provide singular value for each game\n",
    "                prev_sos.append(np.array(prev_prev_avg_results).mean())\n",
    "                prev_sos_all.append(np.array(prev_sos_all_results).mean())\n",
    "                #prev_sos_nc.append(np.array(prev_sos_nc_games).mean())\n",
    "\n",
    "                # take means of SOS data to provide singular value for each game\n",
    "                sos.append(np.array(avg_results).mean())\n",
    "                sos_all.append(np.array(sos_all_results).mean())\n",
    "                sos_nc.append(np.array(sos_nc_games).mean())\n",
    "\n",
    "            opp_df = dataframes[team_dict[name]] # opponent's dataframe\n",
    "\n",
    "            # loops through each game in opponent's dataframe to find the matching date which\n",
    "            # would represent the same game\n",
    "            for idx2, (date, opp) in enumerate(zip(opp_df['Date'], opp_df['Opp_name'])):    # added the name check to account for few times where teams played twice in a day\n",
    "                if (date == date_check) and (opp == name_check):\n",
    "                    opp_data.append(opp_df.loc[idx2]) # appends data from opponent's game\n",
    "                    break\n",
    "\n",
    "            # will loop through each previous opponent of that game's opponent prior to current game\n",
    "            # first checks if idx2 is greater than 0 because there are no games\n",
    "            # before the first game\n",
    "            if idx2 > 0:\n",
    "\n",
    "                # list of opponent's previous opponents before current game\n",
    "                opp_prev_opps = opp_df['Opp_name'][:idx2]\n",
    "\n",
    "                # list that will store average win/loss results for each opponent of current game's opponent\n",
    "                opp_avg_results = []\n",
    "                opp_sos_nc_games = []\n",
    "                opp_prev_opp_prev_results = []\n",
    "\n",
    "                # loop through each previous opponent of opponent\n",
    "                for kk, opp_prev_name in enumerate(opp_prev_opps):\n",
    "                    \n",
    "                    # previous opponent's opponent dataframe\n",
    "                    opp_prev_df = dataframes[team_dict[opp_prev_name]]\n",
    "                    \n",
    "                    len_opp_prev = len(opp_prev_df)\n",
    "                    \n",
    "                    # checks the dates of games of the opponent's previous opponent \n",
    "                    # will look at games prior to current game date\n",
    "                    for idx4, date3 in enumerate(opp_prev_df['Date']):\n",
    "                        if date3 >= date_check:\n",
    "                            opp_prev_avg_result = opp_prev_df['Avg_Result'][idx4]\n",
    "                            opp_prev_opp_prev = opp_prev_df['Opp_name'][:idx4] # opponent's opponent's previous opponents \n",
    "                            break\n",
    "                        elif idx4 == (len_opp_prev - 1):\n",
    "                            opp_prev_avg_result = opp_prev_df['Avg_Result_Fin'][0]\n",
    "                            opp_prev_opp_prev = opp_prev_df['Opp_name']\n",
    "                            break\n",
    "                    \n",
    "                    opp_prev_opp_prev_result = []\n",
    "                        \n",
    "                    for name2 in opp_prev_opp_prev:\n",
    "\n",
    "                        opp_prev_opp_prev_df = dataframes[team_dict[name2]]\n",
    "                        \n",
    "                        len_opp_prev_opp_prev = len(opp_prev_opp_prev_df)\n",
    "\n",
    "                        for ll, date_ll in enumerate(opp_prev_opp_prev_df['Date']):\n",
    "\n",
    "                            if date_ll >= date_check:\n",
    "                                opp_prev_opp_prev_result.append(opp_prev_opp_prev_df['Avg_Result'][ll])\n",
    "                                break\n",
    "                            elif ll == (len_opp_prev_opp_prev - 1):\n",
    "                                opp_prev_opp_prev_result.append(opp_prev_opp_prev_df['Avg_Result_Fin'][0])\n",
    "\n",
    "                    opp_prev_opp_prev_results.append(np.mean(opp_prev_opp_prev_result))\n",
    "                    \n",
    "                    # appends the average result of opponent's opponent's previous games\n",
    "                    opp_avg_results.append(opp_prev_avg_result)\n",
    "\n",
    "                    if kk <= 10:\n",
    "                        opp_sos_nc_games.append(opp_prev_avg_result)\n",
    "\n",
    "                # appends the average results of all opponent's previous opponents previous games\n",
    "                opp_sos.append(np.array(opp_avg_results).mean())\n",
    "                opp_sos_nc.append(np.array(opp_sos_nc_games).mean())\n",
    "                opp_prev_opp_sos.append(np.mean(opp_prev_opp_prev_results))\n",
    "            else:\n",
    "                opp_sos.append(np.nan)\n",
    "                opp_sos_nc.append(np.nan)\n",
    "                opp_prev_opp_sos.append(np.nan)\n",
    "\n",
    "        # Converts the opponents' data to a dataframe and then renames the columns to avoid duplication of column names and \n",
    "        # provide clarity as to what the different columns represent\n",
    "        opp_data_df = pd.DataFrame(opp_data, index = list(range(len(opp_data))))\n",
    "        \n",
    "        columns_dict = {'result': 'result2', 'Mean_Score': 'Mean_Score2', 'Opp_Avg_Score': 'Opp_Avg_Score2', 'Avg_Score': 'Avg_Score2',\n",
    "                        'Avg_Mean_Score': 'Avg_Mean_Score2', 'Avg_Result': 'Avg_Result2', 'Pct_Margin': 'Pct_Margin2', 'Home': 'Home2',\n",
    "                        'Away': 'Away2', 'Neutral': 'Neutral2', 'Date': 'Date2', 'Loc': 'Loc2', 'Opp_name': 'Opp_name2', 'Win': 'Win2',\n",
    "                        'Opp_score': 'Opp_score2', 'Score': 'Score2', 'Threes': 'Threes2', 'Opp_Threes': 'Opp_Threes2',\n",
    "                        'Avg_Threes': 'Avg_Threes2', 'Opp_Avg_Threes': 'Opp_Avg_Threes2', 'Game_Number': 'Game_Number2',\n",
    "                        'Avg_Result_Fin': 'Avg_Result_Fin2', 'Avg_Result_NC': 'Avg_Result_NC2', 'Opp_Avg_FG_Pct': 'Opp_Avg_FG_Pct2',\n",
    "                        'Avg_FG_Pct': 'Avg_FG_Pct2'}\n",
    "        \n",
    "        opp_data_df = opp_data_df.rename(columns = columns_dict)[list(columns_dict.values())]\n",
    "        \n",
    "        # Converts the strength of schedule lists to dataframes that can be appended\n",
    "        sos_df = pd.DataFrame()\n",
    "        sos_df['SOS'] = sos        # Strength of schedule using all previous opponents\n",
    "        sos_df['SOS_NC'] = sos_nc  # Strength of schedule using only non-conference opponentes (first 10 opponents)\n",
    "        sos_df['Opp_SOS'] = opp_sos # Opponent's SOS using all previous opponents\n",
    "        sos_df['Opp_SOS_NC'] = opp_sos_nc\n",
    "        sos_df['Prev_SOS'] = prev_sos\n",
    "        sos_df['SOS_Fin'] = [sos_df['SOS'][len(sos_df) - 1]] * len(sos_df) # column that contains the final SOS\n",
    "        sos_df['SOS_All'] = sos_all\n",
    "        sos_df['SOS_All_Fin'] = [sos_df['SOS_All'][len(sos_df) - 1]] * len(sos_df)\n",
    "        sos_df['Opp_Prev_SOS'] = opp_prev_opp_sos\n",
    "\n",
    "        opp_data_df['Scoring_Pace_Diff'] = (df['Avg_Mean_Score'] - opp_data_df['Avg_Mean_Score2'])/2\n",
    "\n",
    "        # Looks at the relative percentage of points scored and given up by 3-pointers and multiplies that\n",
    "        # by the factor of the oppponent\n",
    "        team_score = df['Avg_Threes'] * opp_data_df['Opp_Avg_Threes2']\n",
    "        opp_score = df['Opp_Avg_Threes'] * opp_data_df['Avg_Threes2']\n",
    "        opp_data_df['Matchup_Comp'] = team_score / (abs(team_score) ** 0.5) \n",
    "        opp_data_df['Opp_Matchup_Comp'] = opp_score / (abs(opp_score) ** 0.5) \n",
    "\n",
    "        # combines original dataframe with data from game opponents, SOS of team, and SOS of opponents\n",
    "        combined_df.append(pd.concat([df, opp_data_df, sos_df], axis = 1))\n",
    "\n",
    "        # saves dataframe\n",
    "        combined_df[ii].to_csv('./Team_Dataframes/' + year + '/Team_Combined/' + teams[ii] + '.csv', index = False)\n",
    "\n",
    "        if ii%20 == 0:\n",
    "            print(ii)\n",
    "    \n",
    "    pd.concat((combined_df)).to_csv('./Team_Dataframes/' + year + 'Combined.csv', index=False)\n",
    "    \n",
    "    # list of concatenated dataframes\n",
    "    return combined_df\n",
    "\n",
    "def plot_params(SEs, STDs, MSEs, CVs, pct_accs, avg_lin_coefss):\n",
    "    \n",
    "    plt.plot(list(range(len(STDs))), STDs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
