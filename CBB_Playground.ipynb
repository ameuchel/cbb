{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import CBB_Funcs as cbb_fun\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error, classification_report\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import statsmodels.api as sm\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, KFold, GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error, accuracy_score\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from playsound import playsound\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE LOADING ALL DATA\n"
     ]
    }
   ],
   "source": [
    "############# Loading in Data ################\n",
    "## The process of scraping all the data from the web for all four years\n",
    "## and performing 'combine_data' could take almost an hour\n",
    "\n",
    "## By setting load = 'True', data is loaded from files that have\n",
    "## already been processed. This can be done for all 4 years in about 15 seconds.\n",
    "\n",
    "## By setting load = 'False', data can either be scraped from the web and then processed (scrape_data = 'True')\n",
    "## or loaded from a file and then processed (scrape_data = 'False'). In the latter scenario, the processing consists of running\n",
    "## the 'combine_data' function.\n",
    "\n",
    "# Get team names and urls\n",
    "teams_source = pd.read_excel('Team_Source.xlsx', header=None, names=['2016', '2016_Teams', '2016 Conf', '2017', '2017_Teams', '2018', '2018_Teams',\n",
    "                                                                     '2019', '2019_Teams', '2020', '2020_Teams', '2021', '2021_Teams'])\n",
    "# select years to be processed\n",
    "years = ['2016', '2017', '2018', '2019']\n",
    "#years = ['2016']\n",
    "\n",
    "# Set data-gathering parameters\n",
    "load = True\n",
    "scrape_data = True\n",
    "\n",
    "# Initialize dataframe\n",
    "cbb_df = pd.DataFrame()\n",
    "\n",
    "# loop through each year to be looked at\n",
    "for yr in years:\n",
    "    if load:\n",
    "        sources, teams, team_dict = cbb_fun.get_logistics(teams_source, yr) # #urls and team names for that year\n",
    "        combined_df = [pd.read_csv('./Team_Dataframes/' + yr + '/Team_Combined/' + teams[ii] + '.csv') for ii in range(len(teams))] # load pre-processing data into list of dataframes   \n",
    "#         with open('./Team_Dataframes/' + yr + '/Combined.pickle', 'rb') as f:\n",
    "#             combined_df = pickle.load(f)\n",
    "        combined_df = []\n",
    "        for ii in range(len(teams)):\n",
    "            with open('./Team_Dataframes/' + yr + '/Team_Combined/' + teams[ii] + '.pickle', 'rb') as f:\n",
    "                combined_df.append(pickle.load(f))\n",
    "        \n",
    "        cbb_df = pd.concat((cbb_df, pd.concat(combined_df))) # concatenate all dataframes to final output dataframe\n",
    "    else:\n",
    "        teams_df, teams, team_dict = cbb_fun.get_team_data(teams_source, yr, scrape_data=scrape_data) # grab data for each team during the 'yr'\n",
    "        combined_df, next_g = cbb_fun.combine_data(teams_df, team_dict, teams, year=yr) # process the data adding information about opponent and previous games\n",
    "        cbb_df = pd.concat((cbb_df, pd.concat((combined_df)))) # concatenate all dataframes to final output dataframe\n",
    "\n",
    "print('DONE LOADING ALL DATA')\n",
    "playsound('mixkit-intro-transition-1146.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NULL STATISTICS\n",
      "Standard Error: 0.07949575963209486\n",
      "Standard Deviation: 14.160959687437149\n",
      "Mean-squared Error: 200.55760746249842\n",
      "Percent Win/Loss Prediction: 50 %\n",
      "\n",
      "\n",
      "HOME NULL CORRECT PREDICTIONS:  63.378092191231474 %\n",
      "\n",
      "\n",
      "LINEAR STATISTICS\n",
      "Standard Error: 0.12452919810409246\n",
      "Standard Deviation: 11.091490680900218\n",
      "Mean-squared Error: 122.8075188149776\n",
      "Percent Win/Loss Prediction:  71.66398588175973 %\n",
      "Cross-validation score: 0.38727317803426964\n",
      "                                 OLS Regression Results                                \n",
      "=======================================================================================\n",
      "Dep. Variable:                 result   R-squared (uncentered):                   0.388\n",
      "Model:                            OLS   Adj. R-squared (uncentered):              0.388\n",
      "Method:                 Least Squares   F-statistic:                              1006.\n",
      "Date:                Thu, 04 Mar 2021   Prob (F-statistic):                        0.00\n",
      "Time:                        16:00:34   Log-Likelihood:                         -91027.\n",
      "No. Observations:               23799   AIC:                                  1.821e+05\n",
      "Df Residuals:                   23784   BIC:                                  1.822e+05\n",
      "Df Model:                          15                                                  \n",
      "Covariance Type:            nonrobust                                                  \n",
      "=====================================================================================\n",
      "                        coef    std err          t      P>|t|      [0.025      0.975]\n",
      "-------------------------------------------------------------------------------------\n",
      "Avg_Result            0.5732      0.131      4.368      0.000       0.316       0.830\n",
      "Avg_Result2          -0.7039      0.132     -5.352      0.000      -0.962      -0.446\n",
      "Home                  3.2097      0.259     12.375      0.000       2.701       3.718\n",
      "Away                 -3.4043      0.260    -13.111      0.000      -3.913      -2.895\n",
      "SOS                   0.6306      0.065      9.654      0.000       0.503       0.759\n",
      "Opp_SOS              -0.6529      0.065    -10.071      0.000      -0.780      -0.526\n",
      "Prev_SOS              1.2588      0.101     12.484      0.000       1.061       1.456\n",
      "Opp_Prev_SOS         -1.2031      0.100    -12.049      0.000      -1.399      -1.007\n",
      "SOS_NC                0.2634      0.052      5.033      0.000       0.161       0.366\n",
      "Opp_SOS_NC           -0.2781      0.052     -5.345      0.000      -0.380      -0.176\n",
      "Opp_Avg_FG_Pct       18.7330      3.047      6.148      0.000      12.761      24.705\n",
      "Opp_Avg_FG_Pct2     -18.6785      3.046     -6.133      0.000     -24.648     -12.709\n",
      "Pct_Margin           18.5638      9.423      1.970      0.049       0.094      37.034\n",
      "Pct_Margin2         -10.1164      9.440     -1.072      0.284     -28.619       8.386\n",
      "Scoring_Pace_Diff    -0.1165      0.028     -4.235      0.000      -0.170      -0.063\n",
      "==============================================================================\n",
      "Omnibus:                       92.538   Durbin-Watson:                   2.003\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              124.793\n",
      "Skew:                           0.029   Prob(JB):                     7.97e-28\n",
      "Kurtosis:                       3.350   Cond. No.                     1.28e+03\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 1.28e+03. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n",
      "Best fit SE: 0.06219339418435837\n",
      "Best fit STD: 11.078806617428864\n",
      "Best fit MSE: 122.68250964599412\n",
      "\n",
      "\n",
      "LOGISITC STATISTICS\n",
      "Score:  71.62967933399939 %\n",
      "Average Coefficients: [[ 0.52988105 -0.52897493  0.26866329 -0.26833112  0.25721528 -0.25874948\n",
      "   0.23679647 -0.23837919  0.11400882 -0.11465719  0.0936609  -0.09382494\n",
      "   0.59481617 -0.59451913 -0.07442316]]\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.71      0.71     15734\n",
      "           1       0.72      0.72      0.72     15998\n",
      "\n",
      "    accuracy                           0.72     31732\n",
      "   macro avg       0.72      0.72      0.72     31732\n",
      "weighted avg       0.72      0.72      0.72     31732\n",
      "\n",
      "\n",
      "\n",
      "RANDOM FOREST STATISTICS\n",
      "Points Spread MSE (Regressor): 127.16784367940474\n",
      "Percent Win/Loss Prediction (Classifier):  70.93156538380805 %\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.67      0.68     15734\n",
      "           1       0.68      0.68      0.68     15998\n",
      "\n",
      "    accuracy                           0.68     31732\n",
      "   macro avg       0.68      0.68      0.68     31732\n",
      "weighted avg       0.68      0.68      0.68     31732\n",
      "\n"
     ]
    }
   ],
   "source": [
    "############# Sending Data to Predictive Models and Looking at Statistics################\n",
    "\n",
    "# determine features to be sent into models\n",
    "features = ['Avg_Result', 'Avg_Result2', 'Home', 'Away', 'SOS', 'Opp_SOS', 'Prev_SOS', 'Opp_Prev_SOS', 'SOS_NC', 'Opp_SOS_NC', 'Opp_Avg_FG_Pct', 'Opp_Avg_FG_Pct2', 'Pct_Margin', 'Pct_Margin2', 'Scoring_Pace_Diff']\n",
    "\n",
    "# number of features\n",
    "num_features = len(features)\n",
    "\n",
    "#data = cbb_df.dropna(subset=features)\n",
    "data = cbb_df[cbb_df['Game_Number'] > 9].dropna(subset=features)\n",
    "\n",
    "data['Opp_Scoring_Pace_Diff'] = data['Scoring_Pace_Diff']*-1\n",
    "\n",
    "opp_features = ['Avg_Result2', 'Avg_Result', 'Home2', 'Away2', 'Opp_SOS', 'SOS', 'Opp_Prev_SOS', 'Prev_SOS', 'Opp_SOS_NC', 'SOS_NC', 'Opp_Avg_FG_Pct2', 'Opp_Avg_FG_Pct', 'Pct_Margin2', 'Pct_Margin', 'Opp_Scoring_Pace_Diff']\n",
    "\n",
    "X = data[list(set(features + opp_features))]\n",
    "y = data['result'] # points spread\n",
    "y2 = data['Win'] # Win (1) or Loss (0) result\n",
    "\n",
    "# Save Results\n",
    "# with open('y.pickle', 'wb') as f:\n",
    "#         pickle.dump(y, f)\n",
    "# with open('y2.pickle', 'wb') as f:\n",
    "#         pickle.dump(y2, f)\n",
    "\n",
    "# Null statistics if winner was chosen at random and points spread was predicted to be 0\n",
    "print('NULL STATISTICS')\n",
    "print('Standard Error:', np.std(y) / np.sqrt(len(y)))\n",
    "print('Standard Deviation:', np.std(y))\n",
    "print('Mean-squared Error:', mean_squared_error(y, [0]*len(y)))\n",
    "print('Percent Win/Loss Prediction: 50 %')\n",
    "\n",
    "# Winner always chosen to be home team - 50/50 for neutral-site games\n",
    "print('\\n\\nHOME NULL CORRECT PREDICTIONS: ', cbb_fun.home_null(cbb_df[['Away', 'Win']]), '%')\n",
    "\n",
    "# Send data to Linear Regression model and get statistics (increase n_runs for stability in results - ~20 sec per 100 runs)\n",
    "SE, STD, MSE, CV, model, pct_acc, avg_lin_coefs, lin_lr =  cbb_fun.get_linear_stats(X, y, features, opp_features, n_runs=500)\n",
    "\n",
    "# Save Average Linear MSE\n",
    "# with open('lin_mse.pickle', 'wb') as f:\n",
    "#         pickle.dump(MSE, f)\n",
    "\n",
    "print('\\n\\nLINEAR STATISTICS')\n",
    "print('Standard Error:', SE)\n",
    "print('Standard Deviation:', STD)\n",
    "print('Mean-squared Error:', MSE)\n",
    "print('Percent Win/Loss Prediction: ', pct_acc, '%')\n",
    "print('Cross-validation score:', CV)\n",
    "print(model.summary())\n",
    "\n",
    "best_fits1 = X[features].dot(avg_lin_coefs)\n",
    "best_fits2 = -1 * (X[opp_features].dot(avg_lin_coefs))\n",
    "best_fits = (best_fits1 + best_fits2) / 2\n",
    "\n",
    "# Save Best fits\n",
    "# with open('best_fits.pickle', 'wb') as f:\n",
    "#         pickle.dump(best_fits, f)\n",
    "\n",
    "# Difference between predicted results and test data\n",
    "resid = best_fits - y\n",
    "\n",
    "# Append statistics\n",
    "print('Best fit SE:', np.std(resid, ddof=num_features) / np.sqrt(np.size(resid)))\n",
    "print('Best fit STD:', np.std(resid, ddof=num_features))\n",
    "print('Best fit MSE:', mean_squared_error(y, best_fits))\n",
    "\n",
    "# Linear Best Fits\n",
    "data['Lin_ypred'] = best_fits\n",
    "\n",
    "# Send data to Logistic Regression model and get statistics (increase n_runs for stability in results - ~30 sec per 100 runs)\n",
    "score, avg_log_coefs, log_lr, sc = cbb_fun.get_logistic_stats(X, y2, features, opp_features, n_runs=100)\n",
    "\n",
    "print('\\n\\nLOGISITC STATISTICS')\n",
    "print('Score: ', score, '%')\n",
    "print('Average Coefficients:', avg_log_coefs)\n",
    "logs = log_lr.predict(sc.transform(X[features]))\n",
    "print('Classification Report\\n', classification_report(y2, logs))\n",
    "\n",
    "# # Grab logistic regression coefficients\n",
    "# with open('log_reg_coef.pickle', 'rb') as f:\n",
    "#     log_reg_coef = pickle.load(f)\n",
    "\n",
    "# Log Best Fits\n",
    "log_best_fit_preds, log_best_fit_probs = cbb_fun.log_best_fit(X[features], X[opp_features], sc, avg_log_coefs)\n",
    "# log_best_fits1 = X[features].dot(avg_lin_coefs)\n",
    "# log_best_fits2 = -1 * (X[opp_features].dot(avg_lin_coefs))\n",
    "# log_best_fits = (best_fits1 + best_fits2) / 2\n",
    "\n",
    "# Add Logistic Regression Predictions to Dataframe\n",
    "data['Log_y2pred'] = log_best_fit_preds\n",
    "data['Log_y2prob'] = log_best_fit_probs\n",
    "\n",
    "# Send Data to RandomForest models and get statistics\n",
    "# This does Regression for the points spread and Classification for the Win/Loss result\n",
    "# Default hyperparameters were selected using results from GridSearchCV tuning \n",
    "rf_mse, rf_acc, rf_reg, rf_class, rf_y_pred, rf_y2_pred = cbb_fun.get_rf_stats(X, y, y2, features, opp_features)\n",
    "\n",
    "# Save RF Values\n",
    "# with open('rf_mse.pickle', 'wb') as f:\n",
    "#         pickle.dump(rf_mse, f)\n",
    "# with open('rf_class.pickle', 'wb') as f:\n",
    "#         pickle.dump(rf_class, f)\n",
    "# with open('rf_reg.pickle', 'wb') as f:\n",
    "#         pickle.dump(rf_reg, f)\n",
    "\n",
    "# Add Random Forest Predictions to Dataframe\n",
    "data['RF_ypred'] = rf_y_pred\n",
    "data['RF_y2pred'] = rf_y2_pred\n",
    "\n",
    "print('\\n\\nRANDOM FOREST STATISTICS')\n",
    "print('Points Spread MSE (Regressor):', rf_mse)\n",
    "print('Percent Win/Loss Prediction (Classifier): ', rf_acc, '%')\n",
    "print('Classification Report\\n', classification_report(y2, rf_class.predict(X[features])))\n",
    "\n",
    "\n",
    "# # Combine Models\n",
    "# mse_av, acc_av, y_tests, y2_tests, y_preds, y2_preds, y2_probs, log_y2_prbs, rf_y2_probs = cbb_fun.combine_models(X, y, y2, features, opp_features, MSE, rf_mse, n_runs=100)\n",
    "\n",
    "# # Save Average MSE and Accuracy\n",
    "# with open('av_mse.pickle', 'wb') as f:\n",
    "#     pickle.dump(mse_av, f)\n",
    "# with open('acc_av.pickle', 'wb') as f:\n",
    "#     pickle.dump(acc_av, f)\n",
    "\n",
    "# print('\\n\\nModel Combination MSE:', mse_av)\n",
    "# print('Model Combination Accuracy:', acc_av)\n",
    "\n",
    "\n",
    "# ## Create Confidence Distributions for Given Scores (ie. percent confidence above below a value)\n",
    "# val_range = np.linspace(-25, 25, 51)\n",
    "# prob_dists = cbb_fun.create_pts_spread_odds(y_preds, y_tests, val_range)\n",
    "# dist_models, xs = cbb_fun.create_models(val_range, prob_dists)\n",
    "\n",
    "# with open('prob_dists.pickle', 'wb') as f:\n",
    "#     pickle.dump(prob_dists, f)\n",
    "# with open('val_range.pickle', 'wb') as f:\n",
    "#     pickle.dump(val_range, f)\n",
    "# with open('dist_models.pickle', 'wb') as f:\n",
    "#     pickle.dump(dist_models, f)\n",
    "\n",
    "        \n",
    "\n",
    "# game_nums = list(range(10, 32))\n",
    "\n",
    "# SEs = []\n",
    "# STDs = []\n",
    "# MSEs = []\n",
    "# CVs = []\n",
    "# pct_accs = []\n",
    "# avg_lin_coefss = []\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# for num in game_nums:\n",
    "    \n",
    "#     if num < 31:\n",
    "#         X = data[data['Game_Number'] == num][features]\n",
    "#         y = data[data['Game_Number'] == num]['result']\n",
    "#     else:\n",
    "#         X = data[data['Game_Number'] >= num][features]\n",
    "#         y = data[data['Game_Number'] >= num]['result']\n",
    "    \n",
    "#     SE, STD, MSE, CV, model, pct_acc, avg_lin_coefs, lr = cbb_fun.get_linear_stats(X, y)\n",
    "    \n",
    "#     #print(num)\n",
    "#     #print(model.summary())\n",
    "    \n",
    "#     SEs.append(SE)\n",
    "#     STDs.append(STD)\n",
    "#     MSEs.append(MSE)\n",
    "#     CVs.append(CV)\n",
    "#     pct_accs.append(pct_acc)\n",
    "#     avg_lin_coefss.append(avg_lin_coefs)\n",
    "    \n",
    "# cbb_fun.plot_params(SEs, STDs, MSEs, CVs, pct_accs, avg_lin_coefss)\n",
    "    \n",
    "playsound('mixkit-intro-transition-1146.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DUKE\n",
      "LinearRegression(fit_intercept=False) model points spread: 3.62\n",
      "\n",
      "LinearRegression(fit_intercept=False) model points spread: -0.99\n",
      "\n",
      "LogisticRegression(max_iter=10000) model prediction: Win (89.0578% probability)\n",
      "\n",
      "LogisticRegression(max_iter=10000) model prediction: Loss (91.6961% probability)\n",
      "\n",
      "\n",
      "EXAMPLE OF WEAK AGREEMENT AMONGST MODELS\n",
      "LinearRegression(fit_intercept=False) model points spread: -0.99\n",
      "\n",
      "LinearRegression(fit_intercept=False) model points spread: 3.62\n",
      "\n",
      "LogisticRegression(max_iter=10000) model prediction: Loss (91.6961% probability)\n",
      "\n",
      "LogisticRegression(max_iter=10000) model prediction: Win (89.0578% probability)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "################ Make Predictions ##################\n",
    "year = '2019'\n",
    "teams_df, teams, team_dict = cbb_fun.get_team_data(teams_source, year, scrape_data=False) # grab data for each team during the 'yr'\n",
    "\n",
    "team1 = 'Duke'\n",
    "team2 = 'Michigan State'\n",
    "\n",
    "#team_feat = ['Avg_Result', 'Avg_Result2', 'Home', 'Away', 'SOS', 'Matchup_Comp', 'Opp_Matchup_Comp', 'Avg_FG_Pct', 'Opp_Avg_FG_Pct', 'Avg_FG_Pct2', 'Opp_Avg_FG_Pct2']\n",
    "team_feat = ['Avg_Result', 'Home', 'Away', 'SOS', 'Matchup_Comp', 'Opp_Matchup_Comp', 'Avg_FG_Pct', 'Opp_Avg_FG_Pct', 'Avg_FG_Pct2', 'Opp_Avg_FG_Pct2']\n",
    "#opp_features = ['Avg_Result2', 'Avg_Result', 'Home2', 'Away2', 'Opp_SOS', 'Opp_Matchup_Comp', 'Matchup_Comp', 'Avg_FG_Pct2', 'Opp_Avg_FG_Pct2', 'Avg_FG_Pct', 'Opp_Avg_FG_Pct']\n",
    "\n",
    "team1 = teams_df[team_dict[team1]]\n",
    "\n",
    "test_pd['Avg_Result'] = team1['Avg_Result_Fin'][0]\n",
    "\n",
    "Team1 = team1.loc[len(team1)- 1][features]\n",
    "#Team1_opp = team1.loc[len(team1)- 1][opp_features]\n",
    "\n",
    "# Models to use for predictions\n",
    "regr_models = [lin_lr]#, rf_reg]\n",
    "class_models = [log_lr]#, rf_class]\n",
    "\n",
    "print('DUKE')\n",
    "# Send data to models\n",
    "reg1 = cbb_fun.regr_predict(regr_models, [Team1])\n",
    "class1 = cbb_fun.class_predict(class_models, [Team1])\n",
    "\n",
    "print()\n",
    "\n",
    "\n",
    "## While most games have strong correlation amongst models,\n",
    "## the game below is an example where there are large disrepancies\n",
    "\n",
    "print('EXAMPLE OF WEAK AGREEMENT AMONGST MODELS')\n",
    "\n",
    "team2 = pd.read_csv('./Team_Dataframes/' + year + '/Team_Only/' + team2 + '.csv')\n",
    "Team2 = team2.loc[len(team2)- 2][features]\n",
    "\n",
    "# Send data to models\n",
    "reg2 = cbb_fun.regr_predict(regr_models, [Team2])\n",
    "class2 = cbb_fun.class_predict(class_models, [Team2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearRegression(fit_intercept=False) model points spread: -7.98\n",
      "\n",
      "RandomForestRegressor(max_depth=8, max_features=8, n_estimators=120) model points spread: -6.12\n",
      "\n",
      "LogisticRegression(max_iter=10000) model prediction: Loss (99.7339% probability)\n",
      "\n",
      "RandomForestClassifier(max_depth=7, max_features=9, n_estimators=134) model prediction: Loss (72.883% probability)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "features = ['Avg_Result', 'Avg_Result2', 'Home', 'Away', 'SOS', 'Opp_SOS', 'Prev_SOS', 'Opp_Prev_SOS', 'SOS_NC', 'Opp_SOS_NC', 'Opp_Avg_FG_Pct', 'Opp_Avg_FG_Pct2', 'Scoring_Pace_Diff']\n",
    "\n",
    "cbb_df['Opp_Scoring_Pace_Diff'] = cbb_df['Scoring_Pace_Diff']*-1\n",
    "\n",
    "opp_features = ['Avg_Result2', 'Avg_Result', 'Home2', 'Away2', 'Opp_SOS', 'SOS', 'Opp_Prev_SOS', 'Prev_SOS', 'Opp_SOS_NC', 'SOS_NC', 'Opp_Avg_FG_Pct2', 'Opp_Avg_FG_Pct', 'Opp_Scoring_Pace_Diff']\n",
    "\n",
    "team1 = cbb_df.iloc[-1]\n",
    "\n",
    "Team1 = team1[features]\n",
    "Team1_opp = team1[opp_features]\n",
    "# Models to use for predictions\n",
    "regr_models = [lin_lr, rf_reg]\n",
    "class_models = [log_lr, rf_class]\n",
    "\n",
    "# Send data to models\n",
    "reg1 = regr_predict(regr_models, [Team1], [Team1_opp])\n",
    "class1 = class_predict(class_models, [Team1], [Team1_opp])\n",
    "\n",
    "\n",
    "# X = data[features]\n",
    "# y = data['result'] # points spread\n",
    "# y2 = data['Win'] # Win (1) or Loss (0) result\n",
    "\n",
    "# rf_regr = RandomForestRegressor()\n",
    "# params = {'n_estimators': range(100, 251, 50), 'max_depth': range(3, X.shape[1]), 'max_features': range(3, X.shape[1])}\n",
    "# cvtree = GridSearchCV(rf_regr, params)\n",
    "# cvtree.fit(X, y)\n",
    "# best_params = cvtree.best_params_\n",
    "# print(best_params)\n",
    "# playsound('mixkit-intro-transition-1146.wav')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regr_predict(models, games, matchups):\n",
    "    \"\"\"\n",
    "        Takes in list of predictive regression models and data to make predictions upon.\n",
    "        \n",
    "        Prints out predictions for each model passed in.\n",
    "    \"\"\"\n",
    "    for ii, game in enumerate(games):\n",
    "        # loop through each of the models passed\n",
    "        for model in models:\n",
    "\n",
    "            # make a prediction based on the model\n",
    "            prediction1 = model.predict([game[0]])\n",
    "            prediction2 = -1 * model.predict([game[1]])\n",
    "            prediction = (prediction1 + prediction2) / 2\n",
    "\n",
    "            # print model and prediction\n",
    "            print(f\"{model} model points spread: {matchups[ii][0]} {round(prediction[0], 2)} to {matchups[ii][1]} ({prediction1, prediction2})\")\n",
    "        print()\n",
    "        \n",
    "def class_predict(models, games, sc, matchups):\n",
    "    \"\"\"\n",
    "        Takes in list of predictive classification models and data to make predictions upon.\n",
    "        \n",
    "        Prints out predictions for each model passed in.\n",
    "    \"\"\"\n",
    "    for ii, game in enumerate(games):\n",
    "        # loop through each of the models passed\n",
    "        for model in models:\n",
    "\n",
    "            # make a prediction based on the model\n",
    "            prediction1 = model.predict(sc.transform([game[0]]))\n",
    "            prediction2 = model.predict(sc.transform([game[1]]))\n",
    "            prediction = prediction1 + prediction2\n",
    "            probability1 = model.predict_proba(sc.transform([game[0]]))[0]\n",
    "            probability2 = model.predict_proba(sc.transform([game[1]]))[0]\n",
    "            print(prediction1, probability1, prediction2, probability2)\n",
    "\n",
    "            # print model and prediction\n",
    "            if prediction == 1:\n",
    "                if prediction1 == 1:\n",
    "                    probability = (probability1[1] + probability2[0]) / 2\n",
    "                    print(f\"{model} model prediction: {matchups[ii][0]} Win ({round(probability * 100, 4)}% probability)\\n\")\n",
    "                else:\n",
    "                    probability = (probability1[0] + probability2[1]) / 2\n",
    "                    print(f\"{model} model prediction: {matchups[ii][0]} Loss ({round(probability * 100, 4)}% probability)\\n\")\n",
    "            else:\n",
    "                print(f\"Undeterminded Winner: (Win probability: {(probability1[1] + probability2[0]) / 2})\")\n",
    "        print()\n",
    "            \n",
    "def get_linear_stats(X, y, features, opp_features, n_runs=10, n_folds=10):\n",
    "    \"\"\"\n",
    "        Takes in X and y data and returns Linear Model statistics.\n",
    "        Returns Standard Error, Standard Deviation, Mean Squared Error,\n",
    "        Cross-Validation Score, and statsmodels OLS results.\n",
    "        \n",
    "        n_runs is the number of training runs to perform. An increase in n_runs\n",
    "        provides more stable results.\n",
    "        \n",
    "        n_folds is the number of folds to create in the cross-validation test\n",
    "    \"\"\"\n",
    "    \n",
    "    # Initialized Linear Regression model\n",
    "    lr = LinearRegression(fit_intercept = False)\n",
    "    \n",
    "    # number for features in model\n",
    "    num_features = len(features)\n",
    "    \n",
    "    # initializes statistics that will be averaged\n",
    "    MSEs = []\n",
    "    SE = []\n",
    "    stds = []\n",
    "    scores = []\n",
    "    pct_acc = []\n",
    "    cv = []\n",
    "    coefs = []\n",
    "    \n",
    "    # Number of training runs\n",
    "    # Increase in runs stabilizes results\n",
    "    for ii in range(n_runs):\n",
    "        \n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "        \n",
    "        # Uses only features\n",
    "        X_train_tm = X_train[features]\n",
    "        X_test_tm = X_test[features]\n",
    "        \n",
    "        lr.fit(X_train_tm, y_train)\n",
    "\n",
    "        y_pred1 = lr.predict(X_test_tm)\n",
    "        \n",
    "        # Uses only opp_features\n",
    "        X_train_opp = X_train[opp_features]\n",
    "        X_test_opp = X_test[opp_features]\n",
    "        \n",
    "        y_pred2 =  -1 * lr.predict(X_test_opp)\n",
    "        \n",
    "        # Difference between predicted results and test data\n",
    "        y_pred = np.mean([y_pred1, y_pred2], axis = 0)\n",
    "        resid = y_pred - y_test\n",
    "        \n",
    "        # Append statistics\n",
    "        SE.append(np.std(resid, ddof=num_features) / np.sqrt(np.size(resid)))\n",
    "        stds.append(np.std(resid, ddof=num_features))\n",
    "        MSEs.append(mean_squared_error(y_test, y_pred))\n",
    "        scores.append(lr.score(X_test_tm, y_test))\n",
    "        \n",
    "         # Show percent accuracy of predicting win/loss\n",
    "        num_correct = 0\n",
    "        for pred, act in zip(y_pred, y_test):\n",
    "            if pred*act > 0:\n",
    "                num_correct += 1\n",
    "        pct_acc.append(num_correct/len(y_test))\n",
    "        \n",
    "        coefs.append(lr.coef_)\n",
    "        \n",
    "        cv.append(cross_val_score(LinearRegression(), X[features], y, cv=KFold(n_folds, shuffle=True)).mean())\n",
    "   \n",
    "    \n",
    "    # Develop OLS model\n",
    "    model = sm.OLS(y_train, X_train_tm, missing = 'drop') # sm.add_constant(X)\n",
    "    results = model.fit()\n",
    "    \n",
    "    return np.mean(SE), np.mean(stds), np.mean(MSEs), np.mean(cv), results, np.mean(pct_acc)*100, np.mean(coefs, axis=0), lr\n",
    "\n",
    "def get_logistic_stats(X, y, features, opp_features, n_runs=10, n_folds=10):\n",
    "    \"\"\"\n",
    "        Takes in X and y data and returns Logistic Model statistics.\n",
    "        Returns Percent Accuracy.\n",
    "        \n",
    "        n_runs is the number of training runs to perform. An increase in n_runs\n",
    "        provides more stable results.\n",
    "        \n",
    "        n_folds is the number of folds to create in the cross-validation test\n",
    "    \"\"\"\n",
    "    \n",
    "    # Initialized Logistic Regression model\n",
    "    lr1 = LogisticRegression(max_iter=10000)\n",
    "    lr2 = LogisticRegression(max_iter=10000)\n",
    "    \n",
    "    # initializes statistics that will be averaged\n",
    "    cv = []\n",
    "    coefs = []\n",
    "    \n",
    "    sc = StandardScaler()\n",
    "    X_cv = sc.fit_transform(X)\n",
    "    \n",
    "    # Number of training runs\n",
    "    # Increase in runs stabilizes results\n",
    "    for ii in range(n_runs):\n",
    "        \n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "        \n",
    "        sc = StandardScaler()\n",
    "        X_train_tm = sc.fit_transform(X_train[features])\n",
    "        X_test_tm = sc.transform(X_test[features])\n",
    "        \n",
    "        lr1.fit(X_train_tm, y_train)\n",
    "\n",
    "         # Uses only opp_features\n",
    "        X_train_opp = sc.transform(X_train[opp_features])\n",
    "        X_test_opp = sc.transform(X_test[opp_features])\n",
    "        \n",
    "        lr2.fit(X_train_opp, y_train)\n",
    "        \n",
    "        avg_coefs = np.mean([lr1.coef_, -1 * lr2.coef_], axis=0)\n",
    "\n",
    "        coefs.append(avg_coefs)\n",
    "        \n",
    "        cv.append(cross_val_score(LogisticRegression(max_iter=10000), X_cv, y, cv=KFold(n_folds, shuffle=True), scoring='accuracy').mean())\n",
    "    \n",
    "    return np.mean(cv)*100, np.mean(coefs, axis=0), lr1, sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "LOGISITC STATISTICS\n",
      "Score:  71.55549909036768 %\n",
      "Average Coefficients: [[ 1.10419436 -1.10159036  0.26531197 -0.26593291  0.25394037 -0.2550779\n",
      "   0.2370644  -0.23890528  0.11642414 -0.11718938  0.08882335 -0.08930684\n",
      "  -0.07394545]]\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.71      0.71     15734\n",
      "           1       0.72      0.72      0.72     15998\n",
      "\n",
      "    accuracy                           0.72     31732\n",
      "   macro avg       0.72      0.72      0.72     31732\n",
      "weighted avg       0.72      0.72      0.72     31732\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# determine features to be sent into models\n",
    "features = ['Avg_Result', 'Avg_Result2', 'Home', 'Away', 'SOS', 'Opp_SOS', 'Prev_SOS', 'Opp_Prev_SOS', 'SOS_NC', 'Opp_SOS_NC', 'Opp_Avg_FG_Pct', 'Opp_Avg_FG_Pct2', 'Scoring_Pace_Diff']\n",
    "\n",
    "# number of features\n",
    "num_features = len(features)\n",
    "\n",
    "#data = cbb_df.dropna(subset=features)\n",
    "data = cbb_df[cbb_df['Game_Number'] > 9].dropna(subset=features)\n",
    "\n",
    "data['Opp_Scoring_Pace_Diff'] = data['Scoring_Pace_Diff']*-1\n",
    "\n",
    "opp_features = ['Avg_Result2', 'Avg_Result', 'Home2', 'Away2', 'Opp_SOS', 'SOS', 'Opp_Prev_SOS', 'Prev_SOS', 'Opp_SOS_NC', 'SOS_NC', 'Opp_Avg_FG_Pct2', 'Opp_Avg_FG_Pct', 'Opp_Scoring_Pace_Diff']\n",
    "\n",
    "X = data[list(set(features + opp_features))]\n",
    "y = data['result'] # points spread\n",
    "y2 = data['Win'] # Win (1) or Loss (0) result\n",
    "\n",
    "# Send data to Logistic Regression model and get statistics (increase n_runs for stability in results - ~30 sec per 100 runs)\n",
    "score, avg_log_coefs, log_lr, sc = get_logistic_stats(X, y2, features, opp_features, n_runs=1)\n",
    "\n",
    "print('\\n\\nLOGISITC STATISTICS')\n",
    "print('Score: ', score, '%')\n",
    "print('Average Coefficients:', avg_log_coefs)\n",
    "logs = log_lr.predict(sc.transform(X[features]))\n",
    "print('Classification Report\\n', classification_report(y2, logs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 10, 'max_features': 7, 'n_estimators': 300}\n"
     ]
    }
   ],
   "source": [
    "features = ['Avg_Result', 'Avg_Result2', 'Home', 'Away', 'SOS', 'Opp_SOS', 'Prev_SOS', 'Opp_Prev_SOS', 'SOS_NC', 'Opp_SOS_NC', 'Opp_Avg_FG_Pct', 'Opp_Avg_FG_Pct2', 'Scoring_Pace_Diff']\n",
    "data = cbb_df[cbb_df['Game_Number'] > 9].dropna(subset=features)\n",
    "\n",
    "opp_features = ['Avg_Result2', 'Avg_Result', 'Home2', 'Away2', 'Opp_SOS', 'SOS', 'Opp_Prev_SOS', 'Prev_SOS', 'Opp_SOS_NC', 'SOS_NC', 'Opp_Avg_FG_Pct2', 'Opp_Avg_FG_Pct', 'Opp_Scoring_Pace_Diff']\n",
    "\n",
    "X = data[features]\n",
    "sc = StandardScaler()\n",
    "Xsc = sc.fit_transform(X)\n",
    "y = data['result'] # points spread\n",
    "y2 = data['Win'] # Win (1) or Loss (0) result\n",
    "\n",
    "rf_class = RandomForestClassifier()\n",
    "rf_regr = RandomForestRegressor()\n",
    "params = {'n_estimators': range(150, 301, 50), 'max_depth': range(6, Xsc.shape[1]), 'max_features': range(3, Xsc.shape[1])}\n",
    "#cvtree = GridSearchCV(rf_class, params)\n",
    "#cvtree.fit(Xsc, y2)\n",
    "cvtree = GridSearchCV(rf_regr, params, scoring='neg_mean_squared_error', n_jobs=2)\n",
    "cvtree.fit(X, y)\n",
    "best_params = cvtree.best_params_\n",
    "print(best_params)\n",
    "playsound('mixkit-intro-transition-1146.wav')\n",
    "# {'max_depth': 9, 'max_features': 8, 'n_estimators': 200} - 70.9788,71.05131 - 100,250,50 - 3,14 - 3,14 - no PctMargins\n",
    "#{'max_depth': 9, 'max_features': 6, 'n_estimators': 175} - 71.0607, 70.9631 - 150,250,25 - 3,13 - 3,13 - no PctMargins\n",
    "#{'max_depth': 12, 'max_features': 3, 'n_estimators': 180} - 71.0638,70.9851 160,220,10 - 3,14 - 3,14 - PctMargins included\n",
    "#{'max_depth': 9, 'max_features': 5, 'n_estimators': 188} - 71.0387, 71.0072 - 170,180,2 - 3,14 - 3,14 - PctMargins included\n",
    "\n",
    "#{'max_depth': 12, 'max_features': 5, 'n_estimators': 250} - 126.0945,125.9407 - 100,250,50 - 3,14 - 3,14 - PctMargins included\n",
    "#{'max_depth': 11, 'max_features': 5, 'n_estimators': 250} - 126.0905,126.2703 - 250,350,50 - 7,14 - 3,10 - PctMargins included\n",
    "#{'max_depth': 11, 'max_features': 8, 'n_estimators': 250} - 126.2227,126.3123 - 150,300,50 - 4,12 - 3,12 - no PctMargins\n",
    "#{'max_depth': 11, 'max_features': 7, 'n_estimators': 255} - 126.1556,126.2016 - 225,275,10 - 6,12 - 3,12 - no PctMargins\n",
    "#{'max_depth': 11, 'max_features': 8, 'n_estimators': 262} - 126.1543,126.5247 - 248,262,2 - 8,12 - 5,12 - no PctMargins\n",
    "#{'max_depth': 10, 'max_features': 7, 'n_estimators': 300} - 126.3155,126.3439 - 150,300,50 - 6,12 - 3,12 - no PctMargins, specified MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-126.34392648988083"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accs = cross_val_score(RandomForestRegressor(n_estimators=300, max_depth=10, max_features=7), \\\n",
    "                       X, y, cv=KFold(10, shuffle=True), scoring='neg_mean_squared_error').mean()\n",
    "accs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['SMA_Result', 'SMA_Result2', 'Home', 'Away', 'SOS', 'Opp_SOS', 'Prev_SOS', 'Opp_Prev_SOS', 'SMA_Pct_Margin', 'SMA_Pct_Margin2', \n",
    "            'Prev_Pct_Margin', 'Prev_Pct_Margin2', 'SOS_NC', 'Opp_SOS_NC', 'EMA_Opp_FG_Pct', 'EMA_Opp_FG_Pct2', 'SMA_Comb_Loc', 'SMA_Comb_Loc2', 'Prev_Comb_Loc', 'Prev_Comb_Loc2',\n",
    "            'Scoring_Pace_Diff', 'Avg_Result_NC', 'Avg_Result_NC2']\n",
    "\n",
    "# number of features\n",
    "num_features = len(features)\n",
    "\n",
    "#data = cbb_df.dropna(subset=features)\n",
    "data = cbb_df[cbb_df['Game_Number'] > 9].dropna(subset=features)\n",
    "\n",
    "X = data[features]\n",
    "y2 = data['Win']\n",
    "\n",
    "sc_grid = StandardScaler()\n",
    "Xsc = sc_grid.fit_transform(X)\n",
    "\n",
    "rf_class = RandomForestClassifier()\n",
    "params = {'n_estimators': range(175, 276, 25), 'max_depth': range(4, Xsc.shape[1]), 'max_features': range(4, Xsc.shape[1])}\n",
    "cvtree = GridSearchCV(rf_class, params)\n",
    "cvtree.fit(Xsc, y2)\n",
    "best_params = cvtree.best_params_\n",
    "print(best_params)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
